{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable importing of utilities\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning up imagery for pre and post rainy season\n",
    "\n",
    "The [previous tutorial](igarrs_chad_01.ipynb) addressed the identifying the extent of the rainy season near Lake Chad. This tutorial will focus on cleaning up optical imagery to make it suitable for water-detection algorithms.  \n",
    "  \n",
    "<br>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What to expect from this notebook\n",
    "\n",
    "- Introduction to landsat 7 data.\n",
    "- basic xarray manipulations  \n",
    "- removing clouds and scanline error using `pixel_qa`\n",
    "- building a composite image  \n",
    "- saving products  \n",
    "\n",
    "<br>  \n",
    "\n",
    "# Algorithmic process  \n",
    "<br>\n",
    "![](diagrams/rainy_demo/alg_jn2_02.png)\n",
    "<br>  \n",
    "The algorithmic process is fairly simple. It is a composable chain of operations on landsat 7 imagery. The goal is to create a **scanline free** and **cloud-free** representation of the data for **pre** and **post** rainy season segments of 2015.  The process is outlined as follows:  \n",
    "\n",
    "1. load landsat imagery data for 2015  \n",
    "2. isolate pre and post rainy season data  \n",
    "3. remove clouds and scan-line errors from pre and post rainy sesaon data.     \n",
    "4. build a cloud free composite for pre and post rainy sesaon data. \n",
    "5. export the data for future use  \n",
    "\n",
    "What scanline-free or cloud-free means will be addressed later in the tutorial. To understand everything, just follow the steps in sequence.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Datacube Object  \n",
    "<br>\n",
    "The following code connects to the datacube and accepts `cloud_removal_in_chad` as an app-name. The app name is typically only used in logging and debugging.  \n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datacube\n",
    "dc = datacube.Datacube(app = \"cloud_removal_in_chad\", config = '/home/localuser/.datacube.conf') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>  \n",
    "\n",
    "Like in the previous tutorial. The datacube object will be used to load data that has previously been ingested by the datacube.  \n",
    "  \n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the boundaries of the area and restricting measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define Geographic boundaries using a (min,max) tuple.\n",
    "latitude = (12.75, 13.0)\n",
    "longitude = (14.25, 14.5)\n",
    "\n",
    "## Specify a date range using a (min,max) tuple  \n",
    "from datetime import datetime\n",
    "time = (datetime(2015,1,1), datetime(2016,1,1))\n",
    "\n",
    "## define the name you gave your data while it was being \"ingested\", as well as the platform it was captured on. \n",
    "platform = 'LANDSAT_7'  \n",
    "product = 'ls7_ledaps_lake_chad_full' \n",
    "\n",
    "measurements = ['red', 'green', 'blue', 'nir', 'swir1', 'swir2','pixel_qa']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a reminder and in-notebook reference, the following line of code displays the extents of the study area.  Re-orient yourself with it.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><iframe src=\"data:text/html;charset=utf-8;base64,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\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x7f750d805748>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.data_cube_utilities.dc_display_map import display_map\n",
    "display_map(latitude = (12.75, 13.0),longitude = (14.25, 14.5))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>  \n",
    "\n",
    "## Loading in Landsat 7 imagery  \n",
    "The following code loads in landsat 7 imagery using the constraints defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Landsat 7 data using parameters,\n",
    "landsat_data = dc.load(latitude = latitude,\n",
    "                       longitude = longitude,\n",
    "                       time = time,\n",
    "                       product = product,\n",
    "                       platform = platform,\n",
    "                       measurements = measurements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='#intro_ls7'></a>  \n",
    "\n",
    "# Explore the Landsat 7 dataset\n",
    "\n",
    "The previous tutorial barely grazed the concept of xarray variables.  \n",
    "To understand how we use landsat7 imagery it will be necessary to make a brief detour and explain it in greater detail. \n",
    "<br>  \n",
    "\n",
    "### xarray - Variables & Data-arrays \n",
    "When you output the contents of your loaded -dataset...    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:    (latitude: 923, longitude: 901, time: 23)\n",
      "Coordinates:\n",
      "  * time       (time) datetime64[ns] 2015-01-04T09:22:48 ... 2015-12-31T09:19:28\n",
      "  * latitude   (latitude) float64 13.0 13.0 13.0 13.0 ... 12.75 12.75 12.75\n",
      "  * longitude  (longitude) float64 14.25 14.25 14.25 14.25 ... 14.5 14.5 14.5\n",
      "Data variables:\n",
      "    red        (time, latitude, longitude) int16 1123 1185 1154 ... -9999 -9999\n",
      "    green      (time, latitude, longitude) int16 1131 1097 1131 ... -9999 -9999\n",
      "    blue       (time, latitude, longitude) int16 851 885 885 ... -9999 -9999\n",
      "    nir        (time, latitude, longitude) int16 2509 2729 2729 ... -9999 -9999\n",
      "    swir1      (time, latitude, longitude) int16 1641 1921 2002 ... -9999 -9999\n",
      "    swir2      (time, latitude, longitude) int16 956 1121 1121 ... -9999 -9999\n",
      "    pixel_qa   (time, latitude, longitude) int32 224 224 224 224 224 ... 1 1 1 1\n",
      "Attributes:\n",
      "    crs:      EPSG:4326\n"
     ]
    }
   ],
   "source": [
    "print(landsat_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>  \n",
    ".. you should notice a list of values called data-variables.\n",
    "\n",
    "<br>  \n",
    "\n",
    "These 'variables' are really 3 dimensional [data-arrays](http://xarray.pydata.org/en/stable/data-structures.html) housing values like 'red', 'green', 'blue', and 'nir', values for each lat,lon,time coordinate pair in your dataset.  Think of an [xarray.Dataset](http://xarray.pydata.org/en/stable/data-structures.html#dataset) as an object that houses many different types of data under a shared coordinate system.  \n",
    "<br>  \n",
    "  \n",
    "![](diagrams/rainy_demo/ls7_xarray.png)  \n",
    "\n",
    "<br>  \n",
    "\n",
    "If you wish to fetch certain  data from your dataset you can call it by its variable name. So, if for example, you wanted to get the near-infrared data-array from the dataset, you would just index it like so:  \n",
    "<br>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'nir' (time: 23, latitude: 923, longitude: 901)>\n",
       "array([[[ 2509,  2729, ...,  1222,  1222],\n",
       "        [ 2509,  2509, ...,  1222,  1266],\n",
       "        ...,\n",
       "        [ 3024,  3068, ...,  3103,  3190],\n",
       "        [ 2981,  2981, ...,  3146,  3276]],\n",
       "\n",
       "       [[ 1947,  2303, ..., -9999, -9999],\n",
       "        [ 1986,  1827, ..., -9999, -9999],\n",
       "        ...,\n",
       "        [ 2809,  2888, ..., -9999, -9999],\n",
       "        [ 2809,  2888, ..., -9999, -9999]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 3171,  3371, ...,   599,   559],\n",
       "        [ 2771,  3371, ...,   599,   559],\n",
       "        ...,\n",
       "        [ 3080,  2801, ...,  2676,  2835],\n",
       "        [ 3080,  2841, ...,  2756,  2835]],\n",
       "\n",
       "       [[-9999, -9999, ..., -9999, -9999],\n",
       "        [-9999, -9999, ..., -9999, -9999],\n",
       "        ...,\n",
       "        [-9999, -9999, ..., -9999, -9999],\n",
       "        [-9999, -9999, ..., -9999, -9999]]], dtype=int16)\n",
       "Coordinates:\n",
       "  * time       (time) datetime64[ns] 2015-01-04T09:22:48 ... 2015-12-31T09:19:28\n",
       "  * latitude   (latitude) float64 13.0 13.0 13.0 13.0 ... 12.75 12.75 12.75\n",
       "  * longitude  (longitude) float64 14.25 14.25 14.25 14.25 ... 14.5 14.5 14.5\n",
       "Attributes:\n",
       "    units:    reflectance\n",
       "    nodata:   -9999\n",
       "    crs:      EPSG:4326"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landsat_data.nir  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>  \n",
    "\n",
    "The object printed above is a [data-array](http://xarray.pydata.org/en/stable/generated/xarray.DataArray.html). Unlike a data-set, data-arrays only house one type of data and has its own set of attributes and functions.   \n",
    "  \n",
    "<br>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xarray - Landsat 7 Values \n",
    "Let's explore landsat datasets in greater detail by starting with some background about what sort of data landsat satellites collect...  \n",
    "  \n",
    "In layman terms, Landsat satellites observe light that is reflected or emitted from the surface of the earth.\n",
    "<br>  \n",
    "  \n",
    "\n",
    "<img src = \"diagrams/rainy_demo/visual_spectrum.jpg\", style=\"width: 600px;\"/>\n",
    "\n",
    "<br>\n",
    "\n",
    "In landsat The spectrum for observable light is split up into smaller sections like 'red', 'green', 'blue', 'thermal','infrared' so-on and so forth...  \n",
    "\n",
    "\n",
    "Each of these sections will have some value denoting how much of that light was reflected from each pixel. The dataset we've loaded in contains values for each of these sections in separate data-arrays under a shared dataset.   \n",
    "\n",
    "The ones used in this series of notebooks are:  \n",
    "\n",
    "- `red`\n",
    "- `green`  \n",
    "- `blue`\n",
    "- `nir` - near infrared\n",
    "- `swir1` - band for short wave infrared \n",
    "- `swir2` - band for short wave infrared\n",
    "\n",
    "There is an alternative band attached to the Landsat7 xarray dataset called pixel qa.\n",
    "\n",
    "- `pixel_qa`  - land cover classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Taking a look at landsat data taken on July 31st, 2015  \n",
    "\n",
    "The data listed above can be used in conjunction to display a visual readout of the area. The code below will use our `red` `green`, and `blue` values to produce a **png** of one of our time slices.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## The only take-away from this code should be that a .png is produced. \n",
    "## Any details about how this function is used is out of scope for this tutorial  \n",
    "\n",
    "from utils.data_cube_utilities.dc_utilities import write_png_from_xr\n",
    "write_png_from_xr('../demo/landsat_rgb.png', landsat_data.isel(time = 11), [\"red\", \"green\", \"blue\"], scale = [(0,2000),(0,2000),(0,2000)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](demo/landsat_rgb.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The need to clean up imagery\n",
    "\n",
    "Considering the imagery above.  It is hard to build a comprehensive profile on landcover. There are several objects that occlude the surface of the earth. Namely errors introduced by an SLC malfunction, as well as cloud cover.  \n",
    "\n",
    "### Scanline Gaps  \n",
    "\n",
    "In May of 2003, Landsat7's scan line correction system failed (SLC). This essentially renders several horizontal rows of imagery unusable for analysis. Luckily, these scanline gaps don't always appear in the same spots.  With enough imagery, a \"gap-less\" representation can be constructed that we can use to analyze pre and post rainy season.  \n",
    "  \n",
    "<br>  \n",
    "\n",
    "![](diagrams/rainy_demo/slc_error_02.PNG)\n",
    "\n",
    "<br>  \n",
    "  \n",
    "  \n",
    "### Cloud occlusion  \n",
    "  \n",
    "Clouds get in the way of analyzing/observing the surface reflectance values of Lake Chad. Fortunately, like SLC gaps, clouds don't always appear in the same spot. With enough imagery, taken at close enough intervals, a \"cloudless\" representation of the area can be built for pre and post rainy season acquisitions of the region.  \n",
    "\n",
    "<br>  \n",
    "  \n",
    "  ![](diagrams/rainy_demo/cloud_clip_01.PNG)\n",
    "  \n",
    "<br>  \n",
    "\n",
    ">**Strong Assumptions**  \n",
    ">In this analysis, strong assumptions are made regarding the variability of lake size in the span of a few acquisitions.(Namely, that the size in a pre-rainy season won't vary as much as it will after the rainy season contributes to the surface area of the lake)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning up Pre and Post rainy season Imagery  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the dataset in two  \n",
    "The first step to cleaning up pre and post rainy season imagery is to split our year's worth of acquisitions into two separate datasets. In the previous notebooks, We've discovered that an appropriate boundary for the rainy season is sometime between June and October. For the sake of this notebook, we'll choose the first day in both months.  \n",
    "<br>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_of_rainy_season = '2015-06-01'\n",
    "end_of_rainy_season   = '2015-10-01'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>  \n",
    "The next step after defining this would be to define the time ranges for both post and pre, then use them to select subsections from the original dataset to act as two separate datasets. (Like in the diagram below)  \n",
    "\n",
    "<br>  \n",
    "\n",
    "![](diagrams/rainy_demo/split_02.png)  \n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_of_year = '2015-01-01'\n",
    "end_of_year   = '2015-12-31'\n",
    "\n",
    "pre  = landsat_data.sel(time = slice(start_of_year, start_of_rainy_season))\n",
    "post = landsat_data.sel(time = slice(end_of_rainy_season, end_of_year))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>  \n",
    "\n",
    "# Building a cloud-free and gap-free representation  \n",
    "\n",
    "This section of the process works s by masking out clouds and gaps from the imagery and then selecting a median valued cloud/scanline-gap free pixels of an image.     \n",
    "  \n",
    "![](diagrams/rainy_demo/cleanup.png)\n",
    "  \n",
    "<br>  \n",
    "  \n",
    "- Masking is done using the **pixel_qa** variable.  \n",
    "- The gap/cloud-free compositing is done using a technique called **median-pixel-mosaicing**   \n",
    "\n",
    "<br>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Masking out clouds and SLC gaps  using `pixel_qa`\n",
    "We're going to be using one of our loaded values called `pixel_qa` for the masking step.  \n",
    "\n",
    "`pixel_qa` doesn't convey surface reflectance intensities. Instead, it is a band that contains more abstract information for each pixel. It places a pixel under one or more of the following categories:    \n",
    "\n",
    "- `clear` - pixel is likely normal landcover  \n",
    "- `water`  - pixel is likely water  \n",
    "- `cloud_shadow`  - pixel is likely in the shadow of a cloud  \n",
    "- `snow` - the pixel is likely snowy  \n",
    "- `cloud` - the pixel is likely cloudy  \n",
    "- `fill` - the pixel is classified as not fit for analysis (SRC-Gaps fall in this classification)  \n",
    "\n",
    "We will use these classifications to mask out values unsuitable for analysis.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Masking Function \n",
    "The masking step will have to make use of a very peculiar encoding for each category.  \n",
    "<br>  \n",
    "\n",
    "\\begin{array}{|c|c|}\n",
    "\\hline bit & value & sum & interpretation \\\\\\hline\n",
    "  \t\t0  & 1 & 1 & Fill \\\\\\hline \n",
    "        1  & 2 & 3 & Clear \\\\\\hline\n",
    "        2  & 4 & 7 & Water \\\\\\hline\n",
    "        3  & 8 & 15 & Cloud Shadow \\\\\\hline\n",
    "        4  & 16 & 31 & Snow \\\\\\hline\n",
    "        5  & 32 & 63 & Cloud \\\\\\hline\n",
    "        6  & 64 & 127 & Cloud Confidence \\\\\n",
    "        &&& 00 = None \\\\\n",
    "        7& 128& 255 & 01 = Low \\\\\n",
    "        &&& 10 = Med \\\\\n",
    "        &&& 11 = High \\\\\\hline \n",
    "        \\end{array}  \n",
    "          \n",
    "<br>  \n",
    "\n",
    "The following function was constructed to mask out anything that isn't **clear** or **water**.  \n",
    "<br>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "\n",
    "def cloud_and_slc_removal_mask(dataset):\n",
    "    #Create boolean Masks for clear and water pixels\n",
    "    clear_pixels = dataset.pixel_qa.values == 2 + 64\n",
    "    water_pixels = dataset.pixel_qa.values == 4 + 64\n",
    "    \n",
    "    a_clean_mask = np.logical_or(clear_pixels, water_pixels)\n",
    "    return a_clean_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>  \n",
    "The following code creates a **boolean** mask, for slc code.  \n",
    "<br>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_for_pre  = cloud_and_slc_removal_mask(pre)\n",
    "mask_for_post = cloud_and_slc_removal_mask(post)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>  \n",
    "A boolean mask is essentially what it sounds like. Let's look at its print-out  \n",
    "\n",
    "<br>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ True  True  True ... False False False]\n",
      "  [ True  True  True ... False False False]\n",
      "  [ True  True  True ...  True  True  True]\n",
      "  ...\n",
      "  [False False False ... False False False]\n",
      "  [False False False ... False False False]\n",
      "  [False False False ...  True  True False]]\n",
      "\n",
      " [[ True  True  True ...  True  True  True]\n",
      "  [ True  True  True ...  True  True  True]\n",
      "  [ True  True  True ...  True  True  True]\n",
      "  ...\n",
      "  [ True  True  True ...  True  True  True]\n",
      "  [ True  True  True ...  True  True  True]\n",
      "  [ True  True  True ...  True  True  True]]\n",
      "\n",
      " [[ True  True  True ... False False False]\n",
      "  [ True  True  True ... False False False]\n",
      "  [ True  True  True ... False False False]\n",
      "  ...\n",
      "  [ True  True  True ... False False False]\n",
      "  [ True  True  True ... False False False]\n",
      "  [ True  True  True ... False False False]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[False False False ... False False False]\n",
      "  [False False False ... False False False]\n",
      "  [False False False ... False False False]\n",
      "  ...\n",
      "  [False False False ... False False False]\n",
      "  [False False False ... False False False]\n",
      "  [False False False ... False False False]]\n",
      "\n",
      " [[ True  True  True ...  True  True  True]\n",
      "  [ True  True  True ...  True  True  True]\n",
      "  [ True  True  True ...  True  True  True]\n",
      "  ...\n",
      "  [ True  True  True ...  True  True  True]\n",
      "  [ True  True  True ...  True  True  True]\n",
      "  [ True  True  True ...  True  True  True]]\n",
      "\n",
      " [[False False False ... False False False]\n",
      "  [False False False ... False False False]\n",
      "  [False False False ... False False False]\n",
      "  ...\n",
      "  [False False False ... False False False]\n",
      "  [False False False ... False False False]\n",
      "  [False False False ... False False False]]]\n"
     ]
    }
   ],
   "source": [
    "print(mask_for_post)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>     \n",
    "\n",
    "This boolean mask contains a **true** value for pixels that are clear and un-occluded by clouds or scanline gaps and **false** values where the opposite is true.  \n",
    "<br>     \n",
    "\n",
    "### Example of mask use   \n",
    "\n",
    "There are many ways to apply a mask. The following example is the xarray way. It will apply *nan* values to areas with clouds or scanline issues:  \n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:    (latitude: 923, longitude: 901, time: 9)\n",
       "Coordinates:\n",
       "  * time       (time) datetime64[ns] 2015-01-04T09:22:48 ... 2015-05-28T09:23:44\n",
       "  * latitude   (latitude) float64 13.0 13.0 13.0 13.0 ... 12.75 12.75 12.75\n",
       "  * longitude  (longitude) float64 14.25 14.25 14.25 14.25 ... 14.5 14.5 14.5\n",
       "Data variables:\n",
       "    red        (time, latitude, longitude) float64 nan nan nan ... nan nan nan\n",
       "    green      (time, latitude, longitude) float64 nan nan nan ... nan nan nan\n",
       "    blue       (time, latitude, longitude) float64 nan nan nan ... nan nan nan\n",
       "    nir        (time, latitude, longitude) float64 nan nan nan ... nan nan nan\n",
       "    swir1      (time, latitude, longitude) float64 nan nan nan ... nan nan nan\n",
       "    swir2      (time, latitude, longitude) float64 nan nan nan ... nan nan nan\n",
       "    pixel_qa   (time, latitude, longitude) float64 nan nan nan ... nan nan nan\n",
       "Attributes:\n",
       "    crs:      EPSG:4326"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre.where(mask_for_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that a lot of the values in the array above have nan values. Compositing algorithms like the **median-pixel mosaic** below, make use of this **where** function as well as 'nans' as the marker for no-data values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>  \n",
    "### Median Pixel Mosaic\n",
    "A median pixel mosaic is used for our cloud/slc-gap free representation of satellite imagery. It Works by masking out clouds/slc-gaps from imagery, and using the median valued cloud-free pixels in the time series of each lat-lon coordinate pair  \n",
    "\n",
    "<br>    \n",
    "![](diagrams/rainy_demo/median_comp.png)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a function we can use to build our mosaic. Its exact mechanics are abstracted away from this tutorial and can be explored in further detail by visiting [our github](https://github.com/ceos-seo/data_cube_utilities/blob/master/dc_mosaic.py).  \n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_cube_utilities.dc_mosaic import create_median_mosaic\n",
    "\n",
    "def mosaic(dataset, mask):\n",
    "    return create_median_mosaic(dataset, clean_mask = mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Lets use it to generate our cloud free representations of the area:  \n",
    "<br>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_pre  = mosaic(pre, mask_for_pre)  \n",
    "clean_post = mosaic(post, mask_for_post)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "# Taking a peek at our cloud-free composites\n",
    "<br>  \n",
    "### Pre Rainy Season  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:    (latitude: 923, longitude: 901)\n",
      "Coordinates:\n",
      "  * latitude   (latitude) float64 13.0 13.0 13.0 13.0 ... 12.75 12.75 12.75\n",
      "  * longitude  (longitude) float64 14.25 14.25 14.25 14.25 ... 14.5 14.5 14.5\n",
      "Data variables:\n",
      "    red        (latitude, longitude) int16 869 905 923 877 ... 1539 1539 1515\n",
      "    green      (latitude, longitude) int16 791 814 786 759 ... 1275 1240 1215\n",
      "    blue       (latitude, longitude) int16 590 614 591 593 ... 843 866 867 891\n",
      "    nir        (latitude, longitude) int16 2001 2303 2261 ... 2610 3001 3001\n",
      "    swir1      (latitude, longitude) int16 1576 2056 2023 ... 2024 2932 3011\n",
      "    swir2      (latitude, longitude) int16 913 1178 1178 1212 ... 1265 2126 2130\n",
      "    pixel_qa   (latitude, longitude) int32 66 66 66 66 66 66 ... 66 66 66 66 66\n"
     ]
    }
   ],
   "source": [
    "print(clean_pre)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_png_from_xr('../demo/pre_rain_mosaic.png', clean_pre, [\"red\", \"green\", \"blue\"], scale = [(0,2000),(0,2000),(0,2000)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your png should look something like this:  \n",
    "![](demo/pre_rain_mosaic.png)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post Rainy Season  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:    (latitude: 923, longitude: 901)\n",
      "Coordinates:\n",
      "  * latitude   (latitude) float64 13.0 13.0 13.0 13.0 ... 12.75 12.75 12.75\n",
      "  * longitude  (longitude) float64 14.25 14.25 14.25 14.25 ... 14.5 14.5 14.5\n",
      "Data variables:\n",
      "    red        (latitude, longitude) int16 638 632 693 693 ... 1030 1165 1338\n",
      "    green      (latitude, longitude) int16 794 752 753 697 ... 945 949 1038 1092\n",
      "    blue       (latitude, longitude) int16 437 467 438 440 ... 595 661 704 738\n",
      "    nir        (latitude, longitude) int16 3440 3486 3266 ... 2552 3035 2956\n",
      "    swir1      (latitude, longitude) int16 1845 2120 2120 ... 1824 2539 2557\n",
      "    swir2      (latitude, longitude) int16 920 997 1017 1072 ... 1045 1546 1634\n",
      "    pixel_qa   (latitude, longitude) int32 66 66 66 66 66 66 ... 66 66 66 66 66\n"
     ]
    }
   ],
   "source": [
    "print(clean_post)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_png_from_xr('../demo/post_rain_mosaic.png', clean_post, [\"red\", \"green\", \"blue\"], scale = [(0,2000),(0,2000),(0,2000)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](demo/post_rain_mosaic.png)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "\n",
    "The [next notebook](igarss_chad_03.ipynb) in the series deals with water classification on these cloud free composites!  We'll need to save our work so that it can be loaded in the next notebook. The good news is that xarrays closely resemble the structure of net NETCDF files. It would make sense to save it off in that format.  The code below saves these files as NETCDFS using built-in export features of xarray.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets drop pixel qa since it doesn't make sense to house it in a composite.  \n",
    "final_post = clean_post.drop('pixel_qa')\n",
    "final_pre  = clean_pre.drop('pixel_qa')\n",
    "\n",
    "final_post.to_netcdf('../demo/post_rain.nc')\n",
    "final_pre.to_netcdf('../demo/pre_rain.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The entire notebook has been condensed down to a about 2 dozen lines of code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datacube\n",
    "from datetime import datetime\n",
    "from utils.data_cube_utilities.dc_mosaic import create_median_mosaic\n",
    "\n",
    "def mosaic(dataset, mask):\n",
    "    return create_median_mosaic(dataset, clean_mask = mask)\n",
    "\n",
    "def cloud_and_slc_removal_mask(dataset):\n",
    "    clear_pixels = dataset.pixel_qa.values == 2 + 64\n",
    "    water_pixels = dataset.pixel_qa.values == 4 + 64\n",
    "    a_clean_mask = np.logical_or(clear_pixels, water_pixels)\n",
    "    return a_clean_mask\n",
    "\n",
    "#datacube obj\n",
    "dc = datacube.Datacube(app = \"cloud_removal_in_chad\", config = '/home/localuser/.datacube.conf') \n",
    "\n",
    "#load params\n",
    "latitude = (12.75, 13.0)\n",
    "longitude = (14.25, 14.5)\n",
    "time = (datetime(2015,1,1), datetime(2016,1,1))\n",
    "\n",
    "platform = 'LANDSAT_7'  \n",
    "product = 'ls7_ledaps_lake_chad_full' \n",
    "measurements = ['red', 'green', 'blue', 'nir', 'swir1', 'swir2','pixel_qa']\n",
    "\n",
    "#load\n",
    "landsat_data = dc.load(latitude = latitude, longitude = longitude, time = time, product = product, platform = platform, measurements = measurements)\n",
    "\n",
    "#time split params\n",
    "start_of_rainy_season = '2015-06-01'\n",
    "end_of_rainy_season   = '2015-10-01'\n",
    "start_of_year = '2015-01-01'\n",
    "end_of_year   = '2015-12-31'\n",
    "\n",
    "#time split\n",
    "pre  = landsat_data.sel(time = slice(start_of_year, start_of_rainy_season))\n",
    "post = landsat_data.sel(time = slice(end_of_rainy_season, end_of_year))\n",
    "\n",
    "#mask for mosaic processs\n",
    "mask_for_pre  = cloud_and_slc_removal_mask(pre)\n",
    "mask_for_post = cloud_and_slc_removal_mask(post)  \n",
    "\n",
    "#mosaic process\n",
    "clean_pre  = mosaic(pre, mask_for_pre)  \n",
    "clean_post = mosaic(post, mask_for_post)\n",
    "\n",
    "#save file\n",
    "clean_pre.drop('pixel_qa').to_netcdf('../demo/pre_01.cd')\n",
    "clean_post.drop('pixel_qa').to_netcdf('../demo/post_01.cd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
