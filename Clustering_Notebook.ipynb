{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id=\"top\"></a>\n",
    "# Clustering Notebook\n",
    "<hr>\n",
    "\n",
    "# Notebook Summary\n",
    "\n",
    "This notebook demonstrates how to use Open Data Cube utilities to cluster geospatial data. \n",
    "\n",
    "<hr><hr>\n",
    "\n",
    "# Outline\n",
    "\n",
    "* [Import Dependencies and Connect to the Data Cube](#import)\n",
    "* [Choose Platform and Product](#plat_prod)\n",
    "* [Get the Maximum Extents of the Cube](#extents)\n",
    "* [Define the Extents of the Analysis](#define_extents) (selecting too much can make the acquisition process slow)\n",
    "* [Load Data from the Data Cube and Create a Composite](#retrieve_data)\n",
    "* [Examine the Composite and Export as a GeoTIFF](#examine_composite)\n",
    "* [Perform Clustering](#cluster)\n",
    "* [Visualize the Clustered Data](#visualize)\n",
    "* [Export the Clustered Data as a GeoTIFF](#export_clustered_data)\n",
    "\n",
    "<hr><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id=\"import\">Import Dependencies and Connect to the Data Cube [&#9652;](#top)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import datacube\n",
    "import datetime as dt\n",
    "import xarray as xr  \n",
    "import numpy as np\n",
    "\n",
    "from utils.data_cube_utilities.data_access_api import DataAccessApi\n",
    "from utils.data_cube_utilities.plotter_utils import figure_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = DataAccessApi(config='/home/localuser/.datacube.conf')\n",
    "dc = api.dc#datacube.Datacube(config='/home/localuser/.datacube.conf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id=\"plat_prod\">Choose Platform and Product [&#9652;](#top)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get available products\n",
    "products_info = dc.list_products()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List LANDSAT 7 products\n",
    "print(\"LANDSAT 7 Products:\")\n",
    "products_info[[\"platform\", \"name\"]][products_info.platform == \"LANDSAT_7\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List LANDSAT 8 products\n",
    "print(\"LANDSAT 8 Products:\")\n",
    "products_info[[\"platform\", \"name\"]][products_info.platform == \"LANDSAT_8\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "product = \"ls7_ledaps_vietnam_sample\"\n",
    "platform = \"LANDSAT_7\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id=\"extents\">Get the Maximum Extents of the Cube [&#9652;](#top)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_cube_utilities.dc_load import get_product_extents\n",
    "\n",
    "full_lat, full_lon, min_max_dates = get_product_extents(api, platform, product)\n",
    "\n",
    "print(\"{}:\".format(platform))\n",
    "print(\"Lat bounds:\", full_lat)\n",
    "print(\"Lon bounds:\", full_lon)\n",
    "print(\"Time bounds:\", min_max_dates) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from utils.data_cube_utilities.dc_display_map import display_map\n",
    "\n",
    "# Display the total shared area available for these datacube products.\n",
    "display_map(latitude = full_lat,longitude = full_lon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id=\"define_extents\">Define the Extents of the Analysis [&#9652;](#top)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Specify start and end dates in the same order as platforms and products**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime \n",
    "# start_date, end_date = (datetime(2010,1,1), datetime(2011,1,1))\n",
    "# start_date, end_date = dt.datetime(2014,1,1), dt.datetime(2016,1,1)\n",
    "start_date, end_date = dt.datetime(2014,9,1), dt.datetime(2015,3,1)\n",
    "date_range = (start_date, end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Specify an area to analyze**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify latitude and longitude bounds of an interesting area within the full extents\n",
    "\n",
    "# Vietnam\n",
    "min_lat_small, max_lat_small = (9.8, 9.85) # Area #1\n",
    "min_lon_small, max_lon_small = (105.1, 105.15) # Area #1\n",
    "\n",
    "lon_small = (min_lon_small, max_lon_small)\n",
    "lat_small = (min_lat_small, max_lat_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize the selected area**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_map(latitude = lat_small,longitude = lon_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id=\"retrieve_data\">Load Data from the Data Cube and Create a Composite [&#9652;](#top)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create geographic chunks for efficient processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_cube_utilities.dc_chunker import create_geographic_chunks\n",
    "\n",
    "geographic_chunks = create_geographic_chunks(\n",
    "                                latitude=lat_small, \n",
    "                                longitude=lon_small, \n",
    "                                geographic_chunk_size=.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a geomedian composite**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils.data_cube_utilities.clean_mask import landsat_qa_clean_mask\n",
    "from utils.data_cube_utilities.dc_mosaic import create_hdmedians_multiple_band_mosaic\n",
    "\n",
    "measurements = ['blue', 'green', 'red', 'nir', 'swir1', 'swir2', 'pixel_qa']\n",
    "product_chunks = []\n",
    "\n",
    "for index, chunk in enumerate(geographic_chunks):\n",
    "    data = dc.load(measurements = measurements,\n",
    "                   time = date_range,\n",
    "                   platform = platform,\n",
    "                   product =  product,\n",
    "                   longitude=chunk['longitude'],\n",
    "                   latitude=chunk['latitude'])\n",
    "    # Mask out clouds and scan lines.\n",
    "    clean_mask = landsat_qa_clean_mask(data, platform)\n",
    "    # Create the mosaic.\n",
    "    product_chunks.append(create_hdmedians_multiple_band_mosaic(data, clean_mask=clean_mask, dtype=np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Combine the chunks to produce the final mosaic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_cube_utilities.dc_chunker import combine_geographic_chunks\n",
    "final_composite = combine_geographic_chunks(product_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id=\"examine_composite\">Examine the Composite and Export as a GeoTIFF [&#9652;](#top)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### True color "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from utils.data_cube_utilities.dc_rgb import rgb\n",
    "\n",
    "fig = plt.figure(figsize=figure_ratio(final_composite, fixed_width=8, fixed_height=8))\n",
    "rgb(final_composite, bands=['red', 'green', 'blue'], fig=fig,\n",
    "    use_data_min=True, use_data_max=True)\n",
    "plt.title('True Color Geomedian Composite', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### False color "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=figure_ratio(final_composite, fixed_width=8, fixed_height=8))\n",
    "rgb(final_composite, bands=['swir1', 'nir', 'red'], fig=fig, \n",
    "    use_data_min=True, use_data_max=True)\n",
    "plt.title('False Color Geomedian Composite', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Example of a composited `swir1` band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "final_composite.swir1.plot(figsize = figure_ratio(final_composite, fixed_width=10, \n",
    "                                               fixed_height=10), cmap = 'magma')\n",
    "plt.title('SWIR1 Composite', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Export to GeoTIFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_cube_utilities.import_export import export_slice_to_geotiff\n",
    "import os\n",
    "geotiff_dir = 'output/geotiffs/Clustering_Notebook'\n",
    "if not os.path.exists(geotiff_dir):\n",
    "    os.makedirs(geotiff_dir)\n",
    "export_slice_to_geotiff(final_composite, '{}/final_composite.tif'.format(geotiff_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id=\"cluster\">Perform Clustering [&#9652;](#top)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_cube_utilities.dc_load import xr_scale_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from utils.data_cube_utilities.dc_clustering import kmeans_cluster_dataset, get_frequency_counts\n",
    "\n",
    "# Bands used for clustering\n",
    "cluster_bands = ['red', 'green', 'blue', 'swir1']\n",
    "\n",
    "classification_4 =  kmeans_cluster_dataset(final_composite, cluster_bands, n_clusters=4)\n",
    "freq_counts_4 =     get_frequency_counts(classification_4)\n",
    "classification_8 =  kmeans_cluster_dataset(final_composite, cluster_bands, n_clusters=8)\n",
    "freq_counts_8 =     get_frequency_counts(classification_8)\n",
    "classification_12 = kmeans_cluster_dataset(final_composite, cluster_bands, n_clusters=12)\n",
    "freq_counts_12 =    get_frequency_counts(classification_12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id=\"visualize\">Visualize the Clustered Data [&#9652;](#top)</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define standard formatting.\n",
    "def get_figsize_geospatial(fixed_width=8, fixed_height=14, \n",
    "                           num_cols=1, num_rows=1):\n",
    "    return figure_ratio(final_composite, \n",
    "                        fixed_width=fixed_width, fixed_height=fixed_height,\n",
    "                        num_cols=num_cols, num_rows=num_rows)\n",
    "xarray_imshow_params = dict(use_colorbar=False, use_legend=True, \n",
    "                            fig_kwargs=dict(dpi=120, figsize=get_figsize_geospatial()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from utils.data_cube_utilities.plotter_utils import xarray_imshow\n",
    "\n",
    "for class_num, freq, fractional_freq in freq_counts_4:\n",
    "    # The `*_cluster_dataset()` functions set -1 as the cluster number for \"rows\" with missing data.\n",
    "    class_num, freq = int(class_num), int(freq)\n",
    "    class_mem_str = \"in class {:d}\".format(class_num) if class_num != -1 else \"that had missing data\"\n",
    "    print(\"There were {:d} data points {}, comprising {:.2%} \"\\\n",
    "          \"of all data points.\".format(int(freq), class_mem_str, \n",
    "                                       fractional_freq))\n",
    "legend_labels = {v:\"Cluster {}\".format(v) if v != -1 else \"Missing Data\" for v in np.unique(classification_4)}\n",
    "xarray_imshow(classification_4, **xarray_imshow_params, legend_labels=legend_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_num, freq, fractional_freq in freq_counts_8:\n",
    "    # The `*_cluster_dataset()` functions set -1 as the cluster number for \"rows\" with missing data.\n",
    "    class_num, freq = int(class_num), int(freq)\n",
    "    class_mem_str = \"in class {:d}\".format(class_num) if class_num != -1 else \"that had missing data\"\n",
    "    print(\"There were {:d} data points {}, comprising {:.2%} \"\\\n",
    "          \"of all data points.\".format(int(freq), class_mem_str, \n",
    "                                       fractional_freq))\n",
    "legend_labels = {v:\"Cluster {}\".format(v) if v != -1 else \"Missing Data\" for v in np.unique(classification_8)}\n",
    "xarray_imshow(classification_8, **xarray_imshow_params, legend_labels=legend_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_num, freq, fractional_freq in freq_counts_12:\n",
    "    # The `*_cluster_dataset()` functions set -1 as the cluster number for \"rows\" with missing data.\n",
    "    class_num, freq = int(class_num), int(freq)\n",
    "    class_mem_str = \"in class {:d}\".format(class_num) if class_num != -1 else \"that had missing data\"\n",
    "    print(\"There were {:d} data points {}, comprising {:.2%} \"\\\n",
    "          \"of all data points.\".format(int(freq), class_mem_str, \n",
    "                                       fractional_freq))\n",
    "legend_labels = {v:\"Cluster {}\".format(v) if v != -1 else \"Missing Data\" for v in np.unique(classification_12)}\n",
    "xarray_imshow(classification_12, **xarray_imshow_params, legend_labels=legend_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id=\"export_clustered_data\">Export the Clustered Data as a GeoTIFF [&#9652;](#top)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_cube_utilities.import_export import export_slice_to_geotiff\n",
    "\n",
    "if not os.path.exists(geotiff_dir):\n",
    "    os.makedirs(geotiff_dir)\n",
    "\n",
    "output_kmeans_cluster4_file_path  =  os.path.join(geotiff_dir, \"cluster4_kmeans.tif\")\n",
    "output_kmeans_cluster8_file_path  =  os.path.join(geotiff_dir, \"cluster8_kmeans.tif\")\n",
    "output_kmeans_cluster12_file_path =  os.path.join(geotiff_dir, \"cluster12_kmeans.tif\")\n",
    "\n",
    "export_slice_to_geotiff(classification_4.to_dataset(name='classification'), \n",
    "                        output_kmeans_cluster4_file_path)\n",
    "export_slice_to_geotiff(classification_8.to_dataset(name='classification'), \n",
    "                        output_kmeans_cluster8_file_path)\n",
    "export_slice_to_geotiff(classification_12.to_dataset(name='classification'), \n",
    "                        output_kmeans_cluster12_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
