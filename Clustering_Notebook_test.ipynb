{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " # Clustering Notebook Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate evenly separable data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "def create_equal_class_separation_dataset(num_clusters):\n",
    "    \"\"\"\n",
    "    Returns an `xarray.Dataset` in the format of output from `datacube.load()`,\n",
    "    which has a clear separation among classes, with all classes having \n",
    "    the same number of points.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    num_clusters: int\n",
    "        The number of clusters. Must be a power of two.\n",
    "    \"\"\"\n",
    "    dims = ['time', 'latitude', 'longitude']\n",
    "    coords = {}\n",
    "    coords['time'] = np.arange(0,1,0.1)\n",
    "    coords['latitude'] = np.arange(0,1,0.1)\n",
    "    coords['longitude'] = np.arange(0,1,1.0/num_clusters)\n",
    "    import math\n",
    "    num_dims = int(math.log(num_clusters,2)) # The number of dimensions to create.\n",
    "    bands = {}\n",
    "    bands['band0'] = xr.DataArray(data=[[list(range(num_clusters))]*10]*10, coords=coords, dims=dims)\n",
    "    cluster_bands = list(bands.keys())\n",
    "    return xr.Dataset(data_vars=bands, coords=coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take a look at the Mosaic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def figure_ratio(ds, fixed_width = 15):\n",
    "    width = fixed_width\n",
    "    height = len(ds.latitude) * (fixed_width / len(ds.longitude))\n",
    "    return (width, height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from utils.data_cube_utilities.dc_clustering import kmeans_cluster_dataset, get_frequency_counts\n",
    "import utils.data_cube_utilities.dc_clustering as dc_clustering\n",
    "import importlib\n",
    "importlib.reload(dc_clustering)\n",
    "def get_classes_and_freq_counts(num_clusters):\n",
    "    dataset = create_equal_class_separation_dataset(num_clusters=num_clusters)\n",
    "    classification = dc_clustering.kmeans_cluster_dataset(dataset, bands=list(dataset.data_vars),\n",
    "                                            n_clusters=num_clusters)\n",
    "    freq_counts = dc_clustering.get_frequency_counts(classification)\n",
    "    return classification, freq_counts\n",
    "classification_4, freq_counts_4 = get_classes_and_freq_counts(4)\n",
    "classification_8, freq_counts_8 = get_classes_and_freq_counts(8)\n",
    "classification_12, freq_counts_12 = get_classes_and_freq_counts(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 100 data points in class 0, comprising 25.00% of all data points.\n",
      "There were 100 data points in class 1, comprising 25.00% of all data points.\n",
      "There were 100 data points in class 2, comprising 25.00% of all data points.\n",
      "There were 100 data points in class 3, comprising 25.00% of all data points.\n"
     ]
    }
   ],
   "source": [
    "for class_num, (freq, fractional_freq) in freq_counts_4:\n",
    "    print(\"There were {} data points in class {}, comprising {:.2%} of all data points.\".format(freq, class_num, fractional_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 100 data points in class 0, comprising 12.50% of all data points.\n",
      "There were 100 data points in class 1, comprising 12.50% of all data points.\n",
      "There were 100 data points in class 2, comprising 12.50% of all data points.\n",
      "There were 100 data points in class 3, comprising 12.50% of all data points.\n",
      "There were 100 data points in class 4, comprising 12.50% of all data points.\n",
      "There were 100 data points in class 5, comprising 12.50% of all data points.\n",
      "There were 100 data points in class 6, comprising 12.50% of all data points.\n",
      "There were 100 data points in class 7, comprising 12.50% of all data points.\n"
     ]
    }
   ],
   "source": [
    "for class_num, (freq, fractional_freq) in freq_counts_8:\n",
    "    print(\"There were {} data points in class {}, comprising {:.2%} of all data points.\".format(freq, class_num, fractional_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 100 data points in class 0, comprising 8.33% of all data points.\n",
      "There were 100 data points in class 1, comprising 8.33% of all data points.\n",
      "There were 100 data points in class 2, comprising 8.33% of all data points.\n",
      "There were 100 data points in class 3, comprising 8.33% of all data points.\n",
      "There were 100 data points in class 4, comprising 8.33% of all data points.\n",
      "There were 100 data points in class 5, comprising 8.33% of all data points.\n",
      "There were 100 data points in class 6, comprising 8.33% of all data points.\n",
      "There were 100 data points in class 7, comprising 8.33% of all data points.\n",
      "There were 100 data points in class 8, comprising 8.33% of all data points.\n",
      "There were 100 data points in class 9, comprising 8.33% of all data points.\n",
      "There were 100 data points in class 10, comprising 8.33% of all data points.\n",
      "There were 100 data points in class 11, comprising 8.33% of all data points.\n"
     ]
    }
   ],
   "source": [
    "for class_num, (freq, fractional_freq) in freq_counts_12:\n",
    "    print(\"There were {} data points in class {}, comprising {:.2%} of all data points.\".format(freq, class_num, fractional_freq))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
