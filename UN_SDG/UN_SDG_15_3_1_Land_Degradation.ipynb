{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a>\n",
    "# UN SDG Indicator 15.3.1:<br> Proportion of land that is degraded over total land area\n",
    "\n",
    "\n",
    "<hr>\n",
    "\n",
    "# Definitions\n",
    "\n",
    "> **Land degradation** is defined as the reduction or loss of the biological or economic productivity and complexity of rain fed cropland, irrigated cropland, or range, pasture, forest and woodlands resulting from a combination of pressures, including land use and management practices. This definition was adopted by and is used by the 196 countries that are Party to the UNCCD.<sup>1</sup>\n",
    "\n",
    "> **Total land area** is the total surface area of a country excluding the area covered by inland waters, like major rivers and lakes.<sup>2</sup>\n",
    "\n",
    "<sup>1</sup> United Nations Convention to Combat Desertification. 1994. Article 1 of the Convention Text http://www2.unccd.int/sites/default/files/relevant-links/2017-01/UNCCD_Convention_ENG_0.pdf\n",
    "\n",
    "<sup>2</sup> Food and Agriculture Organization of the United Nations\n",
    "\n",
    "<hr>\n",
    "\n",
    "# Notebook Summary\n",
    "The United Nations have prescribed 17 \"Sustainable Development Goals\" (SDGs). This notebook attempts to monitor SDG Indicator 15.3.1 - the proportion of land that is degraded over total land area.\n",
    "\n",
    "<hr>\n",
    "\n",
    "# Index\n",
    "\n",
    "* [Import Dependencies and Connect to the Data Cube](#import)\n",
    "* [Choose Platforms and Products](#plat_prod)\n",
    "* [Get the Extents of the Cube](#extents)\n",
    "* [Define the Extents of the Analysis](#define_extents)\n",
    "* [Load the Data](#load_data)\n",
    "    * [Load Data from ESA CCI](#load_esa)\n",
    "    * [Load Data from the Datacube](#load_data_cube)\n",
    "* [Train Random Forest Classifier](#train_cls)\n",
    "    * [Train Model](#train_model)\n",
    "    * [Get Model Score and  Predictions](#get_score_pred)\n",
    "    * [Prepare for Visualization](#prepare_vis)\n",
    "    * [Visualize ESA CCI Data for the Beginning and End of the Time Range](#vis_ESA_CCI)\n",
    "    * [Visualize Predicted Land Classes (Model), and True Land Classes (ESA)](#vis_pred_true_land_cls)\n",
    "* [Visualize Land Change Frequency](#land_change_freq)\n",
    "* [Create Change Matrix](#change_matrix)\n",
    "* [Calculate Peak NDVI Within Classes](#peak_ndvi_within_class)\n",
    "* [Determine NDVI Trend](#ndvi_trend)\n",
    "    * [Fit a Thiel-Sen Regressor to the Mean NDVI Across Time](#thiel_sen_reg)\n",
    "    * [Run the Mann-Kendall Test on the Mean NDVI Across Time to Determine the Trend](#mann_kendall_test)\n",
    "    \n",
    "# Data  Retrieval\n",
    "The ESA CCI data can be retrieved from [this webpage](http://maps.elie.ucl.ac.be/CCI/viewer/download.php). More specifically, we need the one `.tif` file with 24 bands covering years 1992 to 2015, which should be available [here](https://storage.googleapis.com/cci-lc-v207/ESACCI-LC-L4-LCCS-Map-300m-P1Y-1992_2015-v2.0.7.zip).\n",
    "\n",
    "Put that file in `data/ESA_CCI` directory. The `data` directory must be in the root directory of the notebook server, which should be the parent directory of this directory. Unzip it to create a `scratch` folder, which will contain the `.tif` file we need. Move that `.tif` file up into the `data/ESA_CCI` directory and delete the `scratch` folder. You may also delete the `.zip` that was downloaded once the `.tif` has been extracted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id=\"import\">Import Dependencies and Connect to the Data Cube [&#9652;](#top)</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Allow importing of our utilities.\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# Import the datacube and the API\n",
    "import datacube\n",
    "from utils.data_cube_utilities.data_access_api import DataAccessApi\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the datacube and API.\n",
    "api = DataAccessApi(config=\"/home/localuser/.datacube.conf\")\n",
    "dc = api.dc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id=\"plat_prod\">Choose Platforms and Products [&#9652;](#top)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**List available products for each platform**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get available products\n",
    "products_info = dc.list_products()\n",
    "\n",
    "# List LANDSAT 7 products\n",
    "print(\"LANDSAT 7 Products:\")\n",
    "products_info[[\"platform\", \"name\"]][products_info.platform == \"LANDSAT_7\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# List LANDSAT 8 products\n",
    "print(\"LANDSAT 8 Products:\")\n",
    "products_info[[\"platform\", \"name\"]][products_info.platform == \"LANDSAT_8\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Choose products**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the platforms (satellites) and products (datacube sets) \n",
    "# used for this demonstration.\n",
    "use_Landsat7 = True\n",
    "use_Landsat8 = False\n",
    "platforms = []\n",
    "products = []\n",
    "if use_Landsat7:\n",
    "    platforms.append('LANDSAT_7')\n",
    "    products.append('ls7_ledaps_ghana')\n",
    "if use_Landsat8:\n",
    "    platforms.append('LANDSAT_8')\n",
    "    products.append('ls8_lasrc_ghana')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id=\"extents\">Get the Extents of the Cube [&#9652;](#top)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils.data_cube_utilities.dc_display_map import display_map\n",
    "from utils.data_cube_utilities.dc_load import get_overlapping_area\n",
    "\n",
    "# Get the area common to all products.\n",
    "full_lat, full_lon, min_max_dates = get_overlapping_area(api, platforms, products)\n",
    "# Display the total shared area available for these datacube products.\n",
    "display_map(latitude = full_lat, longitude = full_lon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id=\"define_extents\">Define the Extents of the Analysis [&#9652;](#top)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Specify start and end dates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Start and end dates available to both products:\")\n",
    "for platform, min_max_date in zip(platforms, min_max_dates):\n",
    "    print(\"{}:\\n{}\".format(platform, min_max_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a subset of the time available.\n",
    "first_year, last_year = 2000, 2015\n",
    "years = np.arange(first_year,last_year+1)\n",
    "date_ranges = [[dt.datetime(year,1,1), dt.datetime(year,12,31)] for year in years]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Specify an area to analyze**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify latitude and longitude bounds of an interesting area within the full extents.\n",
    "\n",
    "# Ghana\n",
    "# min_lat_small, max_lat_small = (6.5016, 6.5821) # Lake Volta (WOFS Test)\n",
    "# min_lon_small, max_lon_small = (-0.1618, -0.055) # Lake Volta (WOFS Test)\n",
    "# min_lat_small, max_lat_small = (6.5138, 6.5292) # Lake Volta (WOFS Test - small)\n",
    "# min_lon_small, max_lon_small = (-0.1669, -0.1493) # Lake Volta (WOFS Test - small)\n",
    "# min_lat_small, max_lat_small = (10.0, 11.0) # NE Ghana (Land Change)\n",
    "# min_lon_small, max_lon_small = (-0.9, -0.1) # NE Ghana (Land Change)\n",
    "# min_lat_small, max_lat_small = (10.45, 10.55) # NE Ghana (Land Change - small)\n",
    "# min_lon_small, max_lon_small = (-0.55, -0.45) # NE Ghana (Land Change - small)\n",
    "# min_lat_small, max_lat_small = (4.7680, 6.0000) # S Ghana (Land Change - #1)\n",
    "# min_lon_small, max_lon_small = (-2.5405, 1.1110) # S Ghana (Land Change - #1)\n",
    "# min_lat_small, max_lat_small = (5.3180, 5.5500) # S Ghana (Land Change - #2)\n",
    "# min_lon_small, max_lon_small = (-0.6505,-0.4110) # S Ghana (Land Change - #2)\n",
    "# min_lat_small, max_lat_small = (5.2496, 5.8496) # S Ghana (Land Change - #3 - Accra)\n",
    "# min_lon_small, max_lon_small = (-0.7622, 0.1221) # S Ghana (Land Change - #3 - Accra)\n",
    "min_lat_small, max_lat_small = (5.4496, 5.8496) # S Ghana (Land Change - #3 - Accra - small)\n",
    "min_lon_small, max_lon_small = (-0.5622, -0.3221) # S Ghana (Land Change - #3 - Accra - small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize the selected area**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from utils.data_cube_utilities.dc_display_map import display_map\n",
    "lon_small = (min_lon_small, max_lon_small)\n",
    "lat_small = (min_lat_small, max_lat_small)\n",
    "display_map(lat_small, lon_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id=\"load_data\">Load the Data [&#9652;](#top)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Constants ##\n",
    "# Resolution of the ESA CCI land classification data \n",
    "# in degrees per pixel for latitude and longitude (300m x 300m).\n",
    "ESA_CCI_RES = np.array([-0.002777777777778, 0.002777777777778])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id=\"load_esa\">Load Data from ESA CCI [&#9652;](#top)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "\n",
    "def load_ESA_CCI_data(fp='../data/ESA_CCI/ESACCI-LC-L4-LCCS-Map-300m-P1Y-1992_2015-v2.0.7.tif',\n",
    "                      years=None, lat=None, lon=None, num_lat=None, num_lon=None):\n",
    "    \"\"\"\n",
    "    Loads ESA CCI data from a file path to a GeoTIFF. It is yearly data from 1992-2015 at 300m resolution \n",
    "    containing land classifications from the UN Land Cover Classification SYstem (LCCS) \n",
    "    (http://www.fao.org/land-water/land/land-governance/land-resources-planning-toolbox/category/details/en/c/1036361/).\n",
    "\n",
    "    The data covers the entire world with a latitude range of (-90, 90) and a longitude range of (-180, 180).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fp: str\n",
    "        The string filepath to a GeoTIFF containing 24 years of data - 1992-2015.\n",
    "    years: list of int\n",
    "        The years to retrieve data for.\n",
    "    lat, lon: list\n",
    "        Lists of latitude and longitude minimum and maximum values.\n",
    "        The latitude extents are (-90, 90). The longitude extents are (-180, 180).\n",
    "    num_lat, num_lon:\n",
    "        The number of values in the latitude and longitude dimensions to acquire.\n",
    "    \"\"\"\n",
    "    def load_data_np_arr():\n",
    "        with rasterio.open(fp, driver='GTiff') as dst:\n",
    "            data_np_arr = dst.read(indexes=year_inds, window=(list(lat_px_inds), list(lon_px_inds)))\n",
    "            dst.close()\n",
    "        return data_np_arr\n",
    "    \n",
    "    assert years is not None, \"years must be specified\"\n",
    "    assert lat is not None, \"lat must be specified.\"\n",
    "    assert lon is not None, \"lon must be specified.\"\n",
    "\n",
    "    (MIN_LAT, MAX_LAT), (MIN_LON, MAX_LON) = (-90, 90), (-180, 180)\n",
    "    DEGREE_PER_PX = np.abs(ESA_CCI_RES)\n",
    "    PX_PER_DEGREE = 1/DEGREE_PER_PX # About 360.\n",
    "    years, lat, lon = np.array(years), np.array(lat), np.array(lon)\n",
    "    \n",
    "    # Select years.\n",
    "    year_inds = list(years-1991)\n",
    "    # Select area.\n",
    "    # Latitude pixel indices are handled differently than longitude because \n",
    "    # latitude indexing is from top to bottom in this dataset.\n",
    "    lat_px_inds = np.round(PX_PER_DEGREE[0]*(MAX_LAT - lat)).astype(np.int32)[::-1]\n",
    "    lon_px_inds = np.round(PX_PER_DEGREE[1]*(lon - MIN_LON)).astype(np.int32)\n",
    "    \n",
    "    data_np_arr = load_data_np_arr() # Load the data.\n",
    "    # Determine latitude and longitude coordinates.\n",
    "    lat, lon = np.arange(*lat, DEGREE_PER_PX[0])[::-1], np.arange(*lon, DEGREE_PER_PX[1])\n",
    "    # Handle too many coordinates (\"one-off\" errors).\n",
    "    lat, lon = lat[:data_np_arr.shape[1]], lon[:data_np_arr.shape[2]]\n",
    "    return xr.DataArray(data=data_np_arr, coords=[years, lat, lon], dims=['time', 'latitude', 'longitude'])\n",
    "        \n",
    "esa_data = load_ESA_CCI_data(years=years, lat=lat_small, lon=lon_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id=\"load_data_cube\">Load Data from the Datacube [&#9652;](#top)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils.data_cube_utilities.dc_load import load_multiplatform\n",
    "from utils.data_cube_utilities.dc_ndvi_anomaly import NDVI\n",
    "from utils.data_cube_utilities.dc_mosaic import create_hdmedians_multiple_band_mosaic\n",
    "from utils.data_cube_utilities.dc_utilities import ignore_warnings\n",
    "\n",
    "datacube_geomedian_data = [None]*len(years)\n",
    "datacube_ndvi_data = [None]*len(years)\n",
    "year_inds_no_data = [] # A list of indices into the above lists for years with no data.\n",
    "measurements = ['red', 'blue', 'green', 'nir', 'swir1', 'swir2', 'pixel_qa']\n",
    "for year_ind, date_range in enumerate(date_ranges):\n",
    "    # Ignore warning due to xarray indexing into numpy in a deprecated manner\n",
    "    # in `Dataset.interp()`, which is called to alter resolution.\n",
    "    try:\n",
    "        dataset_temp, clean_mask_temp, masks = \\\n",
    "            ignore_warnings(load_multiplatform, dc, platforms, products, \n",
    "                abs_res=(len(esa_data.longitude), len(esa_data.latitude)),\n",
    "                load_params=dict(lat=lat_small, lon=lon_small, time=date_range, \n",
    "                                 measurements=measurements))\n",
    "        cleaned_dataset_temp = dataset_temp.where(clean_mask_temp)\n",
    "        datacube_ndvi_data[year_ind] = NDVI(cleaned_dataset_temp.mean(dim=['latitude', 'longitude', 'time']))\n",
    "        datacube_geomedian_data[year_ind] = create_hdmedians_multiple_band_mosaic(cleaned_dataset_temp, clean_mask_temp)\n",
    "    except AssertionError:\n",
    "        year_inds_no_data.append(year_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_inds_with_data = np.setdiff1d(np.arange(len(years)), year_inds_no_data)\n",
    "years_with_data = years[year_inds_with_data]\n",
    "first_year_with_data, last_year_with_data = years[[0,-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(year_inds_no_data) > 0:\n",
    "    # If all years, the first year, or the last year are missing, the first and last years selected must be changed.\n",
    "    assert_msg_begin = \"The selected combination of platforms, products, and extents have no data \"\n",
    "    assert_msg_end = \" The first and last years with data available are {} and {}.\"\\\n",
    "                     .format(first_year_with_data, last_year_with_data)\n",
    "    # Whether the first and last selected years have data.\n",
    "    first_year_has_data, last_year_has_data = year_inds_no_data[0] != 0, year_inds_no_data[-1] != len(years)-1\n",
    "    assert len(year_inds_no_data) != len(years), assert_msg_begin + \"for any of the selected years.\" + assert_msg_end\n",
    "    assert first_year_has_data, assert_msg_begin + \"for the first selected year.\" + assert_msg_end\n",
    "    assert last_year_has_data, assert_msg_begin + \"for the last selected year.\" + assert_msg_end\n",
    "    assert first_year_has_data or last_year_has_data, assert_msg_begin + \"for the first and last selected years.\" + assert_msg_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For years which have no data and are between the first and last years, \n",
    "# shape them as the other years, but fill with NaNs.\n",
    "geomedian_data_first_year_avail = datacube_geomedian_data[year_inds_with_data[0]]\n",
    "geomedian_data_full_NaNs = xr.full_like(geomedian_data_first_year_avail, np.nan, dtype=np.float64)\n",
    "ndvi_data_first_year_avail = datacube_ndvi_data[year_inds_with_data[0]]\n",
    "ndvi_data_NaN = xr.full_like(ndvi_data_first_year_avail, np.nan, dtype=np.float64) \n",
    "for year_ind in year_inds_no_data:\n",
    "    datacube_geomedian_data[year_ind] = geomedian_data_full_NaNs\n",
    "    datacube_ndvi_data[year_ind] = ndvi_data_NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datacube_ndvi_data = xr.concat(datacube_ndvi_data, dim='time')\n",
    "datacube_ndvi_data.coords['time'] = years#years_with_data\n",
    "datacube_geomedian_data = xr.concat(datacube_geomedian_data, dim='time')\n",
    "datacube_geomedian_data.coords['time'] = years#years_with_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id=\"train_cls\">Train Random Forest Classifier [&#9652;](#top)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id='train_model'>Train Model [&#9652;](#top)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "\n",
    "from utils.data_cube_utilities.dc_utilities import reverse_array_dict\n",
    "\n",
    "# For the feature matrix, make one row for the band values for each pixel for each year.\n",
    "datacube_geomedian_data_arr = datacube_geomedian_data.to_array(dim='data_var').\\\n",
    "                              transpose('time', 'latitude', 'longitude', 'data_var').values\n",
    "num_data_vars = datacube_geomedian_data_arr.shape[-1]\n",
    "datacube_geomedian_data_arr_features = \\\n",
    "    datacube_geomedian_data_arr.reshape((-1,num_data_vars))\n",
    "\n",
    "# Encode data as 6 IPCC land categories.\n",
    "# See the ECA CCI Quick User Guide for these codes and their more detailed meanings.\n",
    "esa_values_for_label = OrderedDict([ # For a label, returns all possible ESA CCI values.\n",
    "    ('Forest Land', np.array([50, 60, 61, 62, 70, 71, 72, 80, 81, 82, 90, 100])),\n",
    "    ('Grassland', np.array([40, 120, 121, 122, 130, 140, 150, 152, 153])),\n",
    "    ('Cropland', np.array([10, 11, 12, 20, 30, 110])),\n",
    "    ('Wetlands', np.array([160, 170, 180])),\n",
    "    ('Settlements', np.array([190])),\n",
    "    ('Other Land', np.array([200, 201, 202, 210, 220])),\n",
    "    ('No Data', np.array([0]))\n",
    "])\n",
    "# For an ESA CCI value, returns the corresponding label.\n",
    "esa_label_for_value = reverse_array_dict(esa_values_for_label)\n",
    "\n",
    "# Encode the data.\n",
    "esa_data_encoded = esa_data.copy() #np.empty_like(esa_data.values)\n",
    "for i, (cls_label, values_for_label) in enumerate(esa_values_for_label.items()):\n",
    "    esa_data_encoded.values[np.isin(esa_data.values, values_for_label)] = i\n",
    "\n",
    "# Flatten ESA data to use as class labels.\n",
    "esa_data_arr_encoded = esa_data_encoded.transpose('time', 'latitude', 'longitude').values\n",
    "\n",
    "# Select only pixels which have valid ESA CCI data.\n",
    "datacube_geomedian_data_arr = datacube_geomedian_data_arr[esa_data_arr_encoded != 6]\n",
    "esa_data_arr_encoded_flat = esa_data_arr_encoded[esa_data_arr_encoded != 6]\n",
    "\n",
    "# Train the model.\n",
    "X, y = datacube_geomedian_data_arr_features, esa_data_arr_encoded_flat\n",
    "# Remove corresponding entries in `X` and `y` where either has NaN values.\n",
    "no_nan_mask = (~np.isnan(X).any(axis=1)) & ~np.isnan(y)\n",
    "X_no_nan, y_no_nan = X[no_nan_mask], y[no_nan_mask]\n",
    "param_grid = {\n",
    "    'n_estimators': [10]\n",
    "}\n",
    "num_folds = 5\n",
    "grid_search = GridSearchCV(RandomForestClassifier(), param_grid,\n",
    "                           scoring=make_scorer(accuracy_score), cv=num_folds)\n",
    "grid_search.fit(X_no_nan, y_no_nan)\n",
    "model, score, best_params = grid_search.best_estimator_, grid_search.best_score_, grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The best parameter set was:\", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id='get_score_pred'>Get Model Score and Predictions [&#9652;](#top)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions.\n",
    "y_pred_no_nan = model.predict(X_no_nan)\n",
    "\n",
    "# Evaluate performance.\n",
    "print(\"Model Cross Validation Score: {0:0.6%} (Stratified {1}-fold)\".format(score, num_folds))\n",
    "print(\"Model Accuracy: {0:0.6%}\".format(accuracy_score(y_no_nan, y_pred_no_nan)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id='prepare_vis'>Prepare for Visualization [&#9652;](#top)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_cube_utilities.plotter_utils import \\\n",
    "    figure_ratio, xarray_imshow, create_discrete_color_map\n",
    "\n",
    "# Determine the class labels to use in visualizations.\n",
    "esa_values_for_label_copy = esa_values_for_label.copy()\n",
    "esa_values_for_label_copy.pop('No Data', None)\n",
    "classes = np.array(list(esa_values_for_label_copy.keys()))\n",
    "num_classes = len(classes)\n",
    "\n",
    "# Reshape land class predictions for visualization.\n",
    "y_pred = np.empty_like(y, dtype=np.float64)\n",
    "y_pred[no_nan_mask] = y_pred_no_nan\n",
    "y_pred[~no_nan_mask] = np.nan\n",
    "dim_lengths_shape = esa_data_encoded.shape\n",
    "y_pred_3D = xr.DataArray(data=y_pred.reshape(dim_lengths_shape), coords=esa_data_encoded.coords, \n",
    "                         dims=esa_data_encoded.dims, attrs=esa_data_encoded.attrs)\n",
    "\n",
    "# Gets figure sizes for plotting geospatial data.\n",
    "def get_figsize_geospatial(fixed_width=10, fixed_height=20):\n",
    "    return figure_ratio(datacube_geomedian_data, \n",
    "                        fixed_width=fixed_width, fixed_height=fixed_height)\n",
    "\n",
    "# Get a mapping of values to labels for legend labelling.\n",
    "legend_labels = {value:label for value, label in enumerate(classes)}\n",
    "# Create a colormap for the predicted and true land classes.\n",
    "map_cmap = create_discrete_color_map((0, len(classes)-1), \n",
    "                                 colors=['red', 'yellow', 'green', 'blue', 'brown', 'black'])\n",
    "# Create a colormap for coloring the cells in the change matrix.\n",
    "change_matrix_cmap = create_discrete_color_map([-1,1], colors=[(255, 204, 204), (189, 215, 238), (198, 224, 180)])\n",
    "\n",
    "title_fontdict = dict(fontsize=20) # Title formatting\n",
    "tick_label_fmt_dict = dict(axis='both', labelsize=12) # Tick label formatting\n",
    "axis_label_fmt_dict = dict(fontsize=16) # Axis label formatting\n",
    "legend_kwargs = dict(fontsize=12, framealpha=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id='vis_ESA_CCI'>Visualize ESA CCI Data for the Beginning and End of the Time Range [&#9652;](#top)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Show true ESA CCI land classes for the first and last years.\n",
    "num_rows, num_cols = 1, 2\n",
    "figsize = get_figsize_geospatial()\n",
    "fig, ax = plt.subplots(num_rows, num_cols, figsize=figsize)\n",
    "fig, ax[0], im, cbar = \\\n",
    "xarray_imshow(esa_data_encoded.sel(time=first_year), fig=fig, ax=ax[0],\n",
    "              use_colorbar=False, use_legend=True,\n",
    "              legend_labels=legend_labels,\n",
    "              title=\"ESA CCI Land Classes for {}\".format(first_year))\n",
    "fig, ax[1], im, cbar = \\\n",
    "    xarray_imshow(esa_data_encoded.sel(time=last_year), fig=fig, ax=ax[1],\n",
    "                  use_colorbar=False, use_legend=True,\n",
    "                  legend_labels=legend_labels,\n",
    "                  title=\"ESA CCI Land Classes for {}\".format(last_year))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id='vis_pred_true_land_cls'>Visualize Predicted Land Classes (Model), and True Land Classes (ESA) [&#9652;](#top)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note that white pixels in the predicted figure are due to missing or masked data, which includes regions occluded by clouds.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Show predicted and true ESA CCI land classes side-by-side for some years.\n",
    "years_to_show = years[0], years[-1] # Select the years you wish to examine.\n",
    "for year in years_to_show:\n",
    "    assert year in years, \\\n",
    "        \"The year {} has not been loaded. Only include years \"\\\n",
    "        \"in the variable 'years_to_show' which are also in the variable 'years'.\".format(year)\n",
    "\n",
    "num_rows, num_cols = len(years_to_show), 2\n",
    "figsize = get_figsize_geospatial()\n",
    "fig, ax = plt.subplots(num_rows, num_cols, figsize=figsize)#, dpi=std_dpi)\n",
    "for year_ind, year in enumerate(years_to_show):\n",
    "    # Show the predicted ESA CCI land classes on the left.\n",
    "    fig, ax[year_ind,0], im, cbar = \\\n",
    "        xarray_imshow(y_pred_3D[year_ind], fig=fig, ax=ax[year_ind,0], \n",
    "                      use_colorbar=False, use_legend=True,\n",
    "                      legend_labels=legend_labels,\n",
    "                      title=\"Predicted Land Classes for {}\".format(year))\n",
    "    # Show the true ESA CCI land classes on the right.\n",
    "    fig, ax[year_ind,1], im, cbar = \\\n",
    "        xarray_imshow(esa_data_encoded.sel(time=year), fig=fig, ax=ax[year_ind,1], \n",
    "                      use_colorbar=False, use_legend=True,\n",
    "                      legend_labels=legend_labels,\n",
    "                      title=\"ESA CCI Land Classes for {}\".format(year))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id=\"land_change_freq\">Visualize Land Change Frequency [&#9652;](#top)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of class changes for each pixel between the first and last years.\n",
    "example_xr = esa_data.isel(time=0)\n",
    "num_cls_changes = xr.DataArray(data=np.zeros_like(example_xr), coords=example_xr.coords, \n",
    "                               dims=example_xr.dims, attrs=example_xr.attrs, \n",
    "                               encoding=example_xr.encoding).astype(np.int8)\n",
    "for time_ind in range(1, len(esa_data.time)):\n",
    "    prev_classes = esa_data.isel(time=time_ind-1)\n",
    "    current_classes = esa_data.isel(time=time_ind)\n",
    "    cls_changes = (current_classes != prev_classes).astype(np.int8)\n",
    "    num_cls_changes += cls_changes\n",
    "unq_num_cls_changes = np.unique(num_cls_changes.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pts_fmt = [None]*len(unq_num_cls_changes)\n",
    "cmap = create_discrete_color_map([min(unq_num_cls_changes),max(unq_num_cls_changes)], \n",
    "                                 pts=unq_num_cls_changes, cmap='viridis', pts_fmt=pts_fmt)\n",
    "\n",
    "figsize = get_figsize_geospatial(fixed_width=6)\n",
    "fig = plt.figure(figsize=figsize)\n",
    "fig, ax, im, cbar = \\\n",
    "    xarray_imshow(num_cls_changes, fig=fig, cbar_labels=unq_num_cls_changes, \n",
    "                  imshow_kwargs=dict(cmap=cmap), cbar_kwargs=dict(ticks=pts_fmt),\n",
    "                  title=\"# Land Class Changes from {} to {}\".format(first_year, last_year))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id=\"change_matrix\">Create Change Matrix [&#9652;](#top)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To specify what transitions are considered positive, neutral, or negative, alter `pos_neu_neg_cng_mat` in the code cell below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from utils.data_cube_utilities.plotter_utils import print_matrix\n",
    "\n",
    "# Get class values for the first and last year.\n",
    "original_year_classes = esa_data_encoded.sel(time=first_year).\\\n",
    "                        transpose('latitude', 'longitude').values.flatten()\n",
    "final_year_classes = esa_data_encoded.sel(time=last_year).\\\n",
    "                     transpose('latitude', 'longitude').values.flatten()\n",
    "\n",
    "# Select only pixels which have valid ESA CCI data.\n",
    "valid_mask = (original_year_classes != 6) & (final_year_classes != 6)\n",
    "original_year_classes, final_year_classes = \\\n",
    "    original_year_classes[valid_mask], final_year_classes[valid_mask]\n",
    "\n",
    "# Get 2-tuples of (original_class, final_class), fill out the change matrix,then convert to percentages of total pixels.\n",
    "original_final_cls = np.stack([original_year_classes, final_year_classes], axis=1)\n",
    "change_matrix = np.zeros((num_classes, num_classes), dtype=np.int32)\n",
    "for orig_cls, final_cls in original_final_cls:\n",
    "    change_matrix[orig_cls, final_cls] += 1\n",
    "change_matrix = change_matrix / change_matrix.sum()\n",
    "\n",
    "# IMPORTANT: This is a matrix specifying each land class transition as positive (1 - green), \n",
    "#            neutral (0 - blue), or negative (-1 - red). Original classes are indexed by row and\n",
    "#            final classes are indexed by column.\n",
    "neg_cng_val, neu_cng_val, pos_cng_val = -1, 0, 1\n",
    "pos_neu_neg_cng_mat = np.array([\n",
    "    # Forest Land  Grassland  Cropland  Wetlands  Settlements  Other Land\n",
    "    [        0,        -1,        -1,        -1,        -1,        -1], # Forest Land\n",
    "    [        1,         0,         1,        -1,        -1,        -1], # Grassland \n",
    "    [        1,        -1,         0,        -1,        -1,        -1], # Cropland \n",
    "    [       -1,        -1,        -1,         0,        -1,        -1], # Wetlands\n",
    "    [        1,         1,         1,         1,         0,         1], # Settlements\n",
    "    [        1,         1,         1,         1,        -1,         0]  # Other Land    \n",
    "])\n",
    "\n",
    "# Create mappings of transitions to values for coloring based on a colormap.\n",
    "cls_trans_for_value = {pos_cng_val:[], neu_cng_val:[], neg_cng_val:[]}\n",
    "for i, orig_class in enumerate(classes):\n",
    "    for j, final_class in enumerate(classes):\n",
    "        pos_neu_neg_cng_val = pos_neu_neg_cng_mat[i,j]\n",
    "        cls_trans_for_value[pos_neu_neg_cng_val].append((orig_class, final_class))\n",
    "value_for_cls_trans = reverse_array_dict(cls_trans_for_value)\n",
    "\n",
    "# Create mappings of transitions to transition type labels (e.g. \"Afforestation\").\n",
    "cls_trans_for_label = {\n",
    "    \"Stable\": [('Forest Land', 'Forest Land'), ('Grassland', 'Grassland'),\n",
    "               ('Cropland', 'Cropland'), ('Wetlands', 'Wetlands'),\n",
    "               ('Settlements', 'Settlements'), ('Other Land', 'Other Land')],\n",
    "    \"Vegetation Loss\": [('Forest Land', 'Grassland'), ('Forest Land', 'Other Land'),\n",
    "                        ('Grassland', 'Other Land'), ('Cropland', 'Other Land')],\n",
    "    \"Deforestation\": [('Forest Land', 'Cropland'), ('Forest Land', 'Settlements'), \n",
    "                      ],\n",
    "    \"Inundation\": [('Forest Land', 'Wetlands'), ('Grassland', 'Wetlands'), \n",
    "                   ('Cropland', 'Wetlands')],\n",
    "    \"Afforestation\": [('Grassland', 'Forest Land'), ('Cropland', 'Forest Land'),\n",
    "                      ('Settlements', 'Forest Land'), ('Other Land', 'Forest Land')],\n",
    "    \"Agricultural Expansion\": [('Grassland', 'Cropland'), ('Settlements', 'Cropland'),\n",
    "                               ('Other Land', 'Cropland')],\n",
    "    \"Urban Expansion\": [('Grassland', 'Settlements'), ('Cropland', 'Settlements'),\n",
    "                        ('Other Land', 'Settlements')],\n",
    "    \"Withdrawl of Agriculture\": [('Cropland', 'Grassland')],\n",
    "    \"Woody Encroachment\": [('Wetlands', 'Forest Land')],\n",
    "    \"Wetland Drainage\": [('Wetlands', 'Grassland'), ('Wetlands', 'Cropland'), \n",
    "                         ('Wetlands', 'Settlements'), ('Wetlands', 'Other Land')],\n",
    "    \"Vegetation Establishment\": [('Settlements', 'Grassland'), ('Other Land', 'Grassland')],\n",
    "    \"Wetland Establishment\": [('Settlements', 'Wetlands'), ('Other Land', 'Wetlands')],\n",
    "    \"Withdrawl of Settlements\": [('Settlements', 'Other Land')],\n",
    "}\n",
    "cls_label_for_trans = reverse_array_dict(cls_trans_for_label)\n",
    "\n",
    "# Create the cell value matrix (used to color cells).\n",
    "cell_value_mtx = np.empty_like(change_matrix)\n",
    "for i, cls_label1 in enumerate(classes):\n",
    "    for j, cls_label2 in enumerate(classes):\n",
    "        cell_value_mtx[i,j] = value_for_cls_trans[(cls_label1, cls_label2)]\n",
    "        \n",
    "# Create the cell label matrix.\n",
    "cell_label_mtx = np.empty_like(change_matrix, dtype=object)\n",
    "for i, cls_label1 in enumerate(classes):\n",
    "    for j, cls_label2 in enumerate(classes):\n",
    "        cell_label_mtx[i,j] = \\\n",
    "            \"{0:.2%}\\n{1}\".format(change_matrix[i,j], \n",
    "                                  cls_label_for_trans[(cls_label1, cls_label2)].replace(\" \", \"\\n\"))\n",
    "\n",
    "# Show the change matrix\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "fig, ax = print_matrix(cell_value_mtx=cell_value_mtx, cell_label_mtx=cell_label_mtx, \n",
    "                       row_labels=classes, col_labels=classes, cmap=change_matrix_cmap, \n",
    "                       cell_val_fmt='s', annot_kwargs=dict(size=14), \n",
    "                       x_axis_tick_kwargs=dict(rotation=0), x_axis_ticks_position='top', fig=fig)\n",
    "ax.yaxis.set_label_position('left')\n",
    "plt.ylabel('Original Class', fontsize=16)\n",
    "ax.xaxis.set_label_position('top')\n",
    "plt.xlabel('Final Class', fontsize=16)\n",
    "plt.title('Change Matrix between {} and {}'.format(first_year, last_year), fontsize=18, pad=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id=\"peak_ndvi_within_class\">Calculate Peak NDVI Within Classes [&#9652;](#top)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get class values for the first and last year.\n",
    "datacube_original_year_data_arr = NDVI(datacube_geomedian_data.sel(time=first_year)[['nir', 'red']]).\\\n",
    "                                  transpose('latitude', 'longitude').values.flatten()\n",
    "datacube_final_year_data_arr = NDVI(datacube_geomedian_data.sel(time=last_year)[['nir', 'red']]).\\\n",
    "                               transpose('latitude', 'longitude').values.flatten()\n",
    "    \n",
    "# Calculate the maximum NDVI for all pixels that are the same class in the first and final years.\n",
    "max_ndvi_per_class = np.zeros(num_classes)\n",
    "for i in range(num_classes):\n",
    "    stable_mask = np.all(original_final_cls == i, axis=1)\n",
    "    class_ndvi_vals = datacube_original_year_data_arr[stable_mask]\n",
    "    max_ndvi_per_class[i] = np.nanmax(class_ndvi_vals) if len(class_ndvi_vals) > 0 else np.nan\n",
    "\n",
    "width = min(18, 3*num_classes)\n",
    "height = width/num_classes\n",
    "print_matrix(max_ndvi_per_class.reshape(1,-1), show_row_labels=False, \n",
    "             col_labels=classes, cmap='Greens', x_axis_tick_kwargs=dict(rotation=0), \n",
    "             x_axis_ticks_position='top', heatmap_kwargs=dict(vmin=-1, vmax=1), \n",
    "             fig_kwargs=dict(figsize=(width,height)))\n",
    "plt.title('Peak NDVI Within Class (no class change between {} and {})'.format(first_year, last_year), \n",
    "          fontsize=14, pad=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id=\"ndvi_trend\">Determine NDVI Trend [&#9652;](#top)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id='thiel_sen_reg'>Fit a Thiel-Sen Regressor to the Mean NDVI Across Time [&#9652;](#top)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_X = datacube_ndvi_data.values\n",
    "regressor_time_pre_fmt = datacube_ndvi_data.time.values\n",
    "regressor_time = regressor_time_pre_fmt.reshape(-1,1)\n",
    "\n",
    "from sklearn.linear_model import TheilSenRegressor\n",
    "regressor = TheilSenRegressor().fit(regressor_time, regressor_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span id='mann_kendall_test'>Run the Mann-Kendall Test on the Mean NDVI Across Time to Determine the Trend [&#9652;](#top)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mann_kendall_test(t, x):\n",
    "    \"\"\"\n",
    "    Runs the Mann-Kendall test to determine a trend in time series data.\n",
    "    \n",
    "    This function is a modified form of the function defined here:\n",
    "        https://up-rs-esp.github.io/mkt/_modules/mkt.html#test\n",
    "    Documentation used includes: \n",
    "        https://up-rs-esp.github.io/mkt/\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    t : 1D numpy.ndarray\n",
    "        Array of the time points of measurements.\n",
    "    x : 1D numpy.ndarray\n",
    "        Array containing the measurements corresponding to entries of 't'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Z_mk: float\n",
    "        The Z-score statistic for the Mann-Kendall test.\n",
    "    \"\"\"\n",
    "    # Calculate signs of all possible differences x_j - x_k, where j > k.\n",
    "    n = len(t)\n",
    "    sgn = np.full(int((n-1)*n/2), 10)\n",
    "    ind = 0\n",
    "    for j in range(n-1):\n",
    "        sgn[ind:ind+(n-1-j)] = np.sign(x[j+1:] - x[j])\n",
    "        ind += n-1-j\n",
    "    \n",
    "    # Calculate the mean of the signs of the differences.\n",
    "    S_mean = sgn.sum()\n",
    "    \n",
    "    # Calculate the variance of the signs of the differences.\n",
    "    unique_x = np.unique(x)\n",
    "    num_tie_groups = len(unique_x)\n",
    "    tie_coef = 0\n",
    "    if num_tie_groups < len(x): # Calculate the tie group coefficient.\n",
    "        for tie_ind in range(num_tie_groups):\n",
    "            tie_val = unique_x[tie_ind]\n",
    "            n_t_g = len(x[x==tie_val]) # The number of ties for this tie group.\n",
    "            tie_coef += n_t_g*(n_t_g-1)*(2*n_t_g+5)\n",
    "    varS = (n*(n-1)*(2*n+5) - tie_coef)/18\n",
    "    \n",
    "    # Compute the Z-score based on above estimated mean and variance\n",
    "    if S_mean > 0:\n",
    "        Z_mk = (S_mean-1)/np.sqrt(varS)\n",
    "    if S_mean == 0:\n",
    "        Z_mk = 0\n",
    "    if S_mean < 0:\n",
    "        Z_mk = (S_mean+1)/np.sqrt(varS)\n",
    "    \n",
    "    return Z_mk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "z_score = mann_kendall_test(regressor_time_pre_fmt, regressor_X)\n",
    "\n",
    "z_score_label = None\n",
    "if z_score < -1.96:\n",
    "    z_score_label = \"Potential Degradation\"\n",
    "if (-1.96 < z_score) and (z_score < 1.96):\n",
    "    z_score_label = \"No Significant Change\"\n",
    "if 1.96 < z_score:\n",
    "    z_score_label = \"Potential Improvement\"\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(regressor_time_pre_fmt, regressor_X, label='Original Data')\n",
    "plt.plot(regressor_time_pre_fmt, regressor.predict(regressor_time), label='Mann-Kendall Regression')\n",
    "plt.legend()\n",
    "plt.title(\"NDVI Trend - Mann-Kendall Z score: {:.3f} - {}\".format(z_score, z_score_label))\n",
    "plt.xticks(regressor_time_pre_fmt)\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"NDVI\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
