{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CEOS Data Cube - Water Analysis Notebook\n",
    "*****\n",
    "**Description:** This Python notebook allows users to directly interact with a CEOS-formatted data cube to perform analyses for water management. The following steps will allow users to connect to a data cube, define the analysis location and time period (extent of latitude/longitude and dates), and then run the Australian Water Observations from Space (WOFS) algorithm. The outputs of the WOFS algorithm include static and time series pixel-level water observations for any pixel. These results provide critical information for water management that will allow users to assess water cycle dynamics, historical water extent and the risk of floods and droughts. Future versions may consider the addition of water quality parameters (e.g. Total Suspended Matter, Chlorophyll-A, CDOM), coastal erosion analyses and in-situ precipitation and surface temperature data.\n",
    "*****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import necessary Data Cube libraries and dependencies.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "import datacube\n",
    "from dc_water_classifier import wofs_classify\n",
    "from dc_utilities import perform_timeseries_analysis\n",
    "import dc_au_colormaps\n",
    "\n",
    "from dc_notebook_utilities import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First, we must connect to our data cube.** We can then query the contents of the data cube we have connected to, including both the metadata and the actual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dc = datacube.Datacube(app='dc-water-analysis')\n",
    "api = datacube.api.API(datacube=dc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obtain the metadata of our cube...** Initially, we need to get the platforms and products in the cube. The rest of the metadata will be dependent on these two options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get available products\n",
    "products = dc.list_products()\n",
    "platform_names = list(set(products.platform))\n",
    "product_names = list(products.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Execute the following code and then use the generated form to choose your desired platfrom and product.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "product_values = create_platform_product_gui(platform_names, product_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With the platform and product, we can get the rest of the metadata.** This includes the resolution of a pixel, the latitude/longitude extents, and the minimum and maximum dates available of the chosen platform/product combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save the form values\n",
    "platform = product_values[0].value\n",
    "product = product_values[1].value\n",
    "\n",
    "# Get the pixel resolution of the selected product\n",
    "resolution = products.resolution[products.name == product]\n",
    "lat_dist = resolution.values[0][0]\n",
    "lon_dist = resolution.values[0][1]\n",
    "\n",
    "# Get the extents of the cube\n",
    "descriptor = api.get_descriptor({'platform': platform})[product]\n",
    "\n",
    "min_date = descriptor['result_min'][0]\n",
    "min_lat = descriptor['result_min'][1]\n",
    "min_lon = descriptor['result_min'][2]\n",
    "\n",
    "min_date_str = str(min_date.year) + '-' + str(min_date.month) + '-' + str(min_date.day)\n",
    "\n",
    "min_lat_rounded = round(min_lat, 3)\n",
    "min_lon_rounded =  round(min_lon, 3)\n",
    "\n",
    "max_date = descriptor['result_max'][0]\n",
    "max_lat = descriptor['result_max'][1] \n",
    "max_lon = descriptor['result_max'][2] \n",
    "\n",
    "max_date_str = str(max_date.year) + '-' + str(max_date.month) + '-' + str(max_date.day)\n",
    "\n",
    "max_lat_rounded = round(max_lat, 3) #calculates latitude of the pixel's center\n",
    "max_lon_rounded = round(max_lon, 3) #calculates longitude of the pixel's center\n",
    "\n",
    "# Display metadata\n",
    "generate_metadata_report(min_date_str, max_date_str, \n",
    "                         min_lon_rounded, max_lon_rounded, lon_dist,\n",
    "                         min_lat_rounded, max_lat_rounded, lat_dist)\n",
    "\n",
    "#show_map_extents(min_lon_rounded, max_lon_rounded, min_lat_rounded, max_lat_rounded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Execute the following code and then use the generated form to choose the extents of your desired data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "extent_values = create_extents_gui(min_date_str, max_date_str,\n",
    "                                   min_lon_rounded, max_lon_rounded,\n",
    "                                   min_lat_rounded, max_lat_rounded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now that we have filled out the above two forms, we have enough information to query our data cube.** The following code snippet ends with the actual Data Cube query, which will return the dataset with all the data matching our query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save form values\n",
    "start_date = datetime.strptime(extent_values[0].value, '%Y-%m-%d')\n",
    "end_date = datetime.strptime(extent_values[1].value, '%Y-%m-%d')\n",
    "min_lon = extent_values[2].value\n",
    "max_lon = extent_values[3].value\n",
    "min_lat = extent_values[4].value\n",
    "max_lat = extent_values[5].value\n",
    "\n",
    "# Query the Data Cube\n",
    "dataset_in = dc.load(platform=platform,\n",
    "                     product=product,\n",
    "                     time=(start_date, end_date),\n",
    "                     lon=(min_lon, max_lon), \n",
    "                     lat=(min_lat, max_lat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**At this point, we have finished accessing our data cube and we can turn to analyzing our data.** In this example, we will run the WOfS algorithm. The wofs_classify function, seen below, will return a modified dataset, where a value of 1 indicates the pixel has been classified as water by the WoFS algorithm and 0 represents the pixel is non-water.\n",
    "\n",
    "*****\n",
    "\n",
    "For more information on the WOfS algorithm, refer to:\n",
    "\n",
    "Mueller, et al. (2015) \"Water observations from space: Mapping surface water from 25 years of Landsat imagery across Australia.\" *Remote Sensing of Environment*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "water_class = wofs_classify(dataset_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Execute the following code and then use the generated form to choose your desired acquisition date.** The following two code blocks are only necessary if you would like to see the water mask of a single acquisition date. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "acq_dates = list(water_class.time.values.astype(str))\n",
    "acq_date_input = create_acq_date_gui(acq_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save form value\n",
    "acq_date = acq_date_input.value\n",
    "acq_date_index = acq_dates.index(acq_date)\n",
    "\n",
    "# Get water class for selected acquisition date and mask no data values\n",
    "water_class_for_acq_date = water_class.wofs[acq_date_index]\n",
    "water_class_for_acq_date.values = water_class_for_acq_date.values.astype('float')\n",
    "water_class_for_acq_date.values[water_class_for_acq_date.values == -9999] = np.nan\n",
    "\n",
    "water_observations_for_acq_date_plot = water_class_for_acq_date.plot(cmap='BuPu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With all of the pixels classified as either water/non-water, let's perform a time series analysis over our derived water class.** The function, perform_timeseries_analysis, takes in a dataset of 3 dimensions (time, latitude, and longitude), then sums the values of each pixel over time. It also keeps track of the number of clear observations we have at each pixel. We can then normalize each pixel to determine areas at risk of flooding. The normalization calculation is simply:\n",
    "\n",
    "$$normalized\\_water\\_observations = \\dfrac{total\\_water\\_observations}{total\\_clear\\_observations}$$.\n",
    "\n",
    "The output each of the three calculations can be seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time_series = perform_timeseries_analysis(water_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The following plots visualize the results of our timeseries analysis.** You may change the color scales with the cmap option. For color scales available for use by cmap, see http://matplotlib.org/examples/color/colormaps_reference.html. You can also define discrete color scales by using the levels and colors. For example:\n",
    "\n",
    "* normalized_water_observations_plot = normalized_water_observations.plot(levels=3, colors=['#E5E5FF', '#4C4CFF', '#0000FF'])\n",
    "* normalized_water_observations_plot = normalized_water_observations.plot(levels=[0.00, 0.50, 1.01], colors=['#E5E5FF', '#0000FF'])\n",
    "\n",
    "For more examples on how you can modify plots, see http://xarray.pydata.org/en/stable/plotting.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normalized_water_observations_plot = time_series.normalized_data.plot(cmap='dc_au_WaterSummary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_water_observations_plot = time_series.total_data.plot(cmap='dc_au_WaterObservations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_clear_observations_plot = time_series.total_clean.plot(cmap='dc_au_ClearObservations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
