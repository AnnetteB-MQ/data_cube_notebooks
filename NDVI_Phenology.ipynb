{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a>\n",
    "# NDVI Phenology\n",
    "<hr>\n",
    "\n",
    "# Notebook Summary\n",
    "\n",
    "* LANDSAT 7, LANDSAT 8, or both are used to detect changes in plant life over time.\n",
    "\n",
    "<hr>\n",
    "\n",
    "# Algorithmic process  \n",
    "\n",
    "* [Import Dependencies and Connect to the Data Cube](#import)\n",
    "* [Choose Platform and Product](#plat_prod)\n",
    "* [Get the Maximum Extents of the Cube](#extents)\n",
    "* [Define the Extents of the Analysis](#define_extents) (selecting too much can make the acquisition process slow)\n",
    "* [Load Data from the Data Cube](#retrieve_data)\n",
    "* [Calculate NDVI](#calculate)\n",
    "* [Examine the Selected Area](#area_analysis)\n",
    "* [Create a Max NDVI Composite](#mosaic)\n",
    "* [Export the Mosaic to a PNG and a GeoTIFF](#export)\n",
    "\n",
    "<hr>\n",
    "\n",
    "# How It Works\n",
    "\n",
    "To detect changes in plant life, we use a measure called NDVI. \n",
    "* <font color=green>NDVI</font> is the ratio of the difference between the amount of near infrared light <font color=red>(NIR)</font> and red light <font color=red>(RED)</font> divided by their sum.\n",
    "<br>\n",
    "\n",
    "$$ NDVI =  \\frac{(NIR - RED)}{(NIR + RED)}$$  \n",
    "\n",
    "<br>\n",
    "<div class=\"alert-info\">\n",
    "The intention is to observe how much red light is being absorbed versus reflected. Photosynthetic plants absorb most of the visible spectrum's wavelengths when they are healthy. When they aren't healthy, more of that light will get reflected.  This makes the difference between <font color=red>NIR</font> and <font color=red>RED</font> much smaller, which will lower the <font color=green>NDVI</font>.  The resulting values from doing this over several pixels can be used to create visualizations for the changes in the amount of photosynthetic vegetation in large areas.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id=\"import\">Import Dependencies and Connect to the Data Cube [&#9652;](#top)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "# Supress Warning \n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import the datacube and the API\n",
    "import datacube\n",
    "from utils.data_cube_utilities.data_access_api import DataAccessApi\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the datacube and API.\n",
    "api = DataAccessApi(config=\"/home/localuser/.datacube.conf\")\n",
    "dc = api.dc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id=\"plat_prod\">Choose Platform and Product [&#9652;](#top)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get available products\n",
    "products_info = dc.list_products()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List LANDSAT 7 products\n",
    "print(\"LANDSAT 7 Products:\")\n",
    "products_info[[\"platform\", \"name\"]][products_info.platform == \"LANDSAT_7\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# List LANDSAT 8 products\n",
    "print(\"LANDSAT 8 Products:\")\n",
    "products_info[[\"platform\", \"name\"]][products_info.platform == \"LANDSAT_8\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the platforms (satellites) and products (datacube sets) \n",
    "# used for this demonstration.\n",
    "use_Landsat7 = True\n",
    "use_Landsat8 = True\n",
    "platforms = []\n",
    "products = []\n",
    "if use_Landsat7:\n",
    "    platforms.append('LANDSAT_7')\n",
    "    products.append('ls7_ledaps_ghana')\n",
    "if use_Landsat8:\n",
    "    platforms.append('LANDSAT_8')\n",
    "    products.append('ls8_lasrc_ghana')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id=\"extents\">Get the Maximum Extents of the Cube [&#9652;](#top)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for product, platform in zip(products, platforms):\n",
    "    prod_extents = api.get_query_metadata(platform=platform, product=product, measurements=[])\n",
    "\n",
    "    latitude_extents = prod_extents['lat_extents']\n",
    "    longitude_extents = prod_extents['lon_extents']\n",
    "    time_extents = list(map(lambda time: time.strftime('%Y-%m-%d'), prod_extents['time_extents']))\n",
    "\n",
    "    print(\"{}:\".format(platform))\n",
    "    print(\"Lat bounds:\", latitude_extents)\n",
    "    print(\"Lon bounds:\", longitude_extents)\n",
    "    print(\"Time bounds:\", time_extents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from utils.data_cube_utilities.dc_load import get_overlapping_area\n",
    "from utils.data_cube_utilities.dc_display_map import display_map\n",
    "\n",
    "full_lat, full_lon, min_max_dates = get_overlapping_area(api, platforms, products)\n",
    "\n",
    "# Display the total shared area available for these datacube products.\n",
    "display_map(latitude = full_lat,longitude = full_lon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id=\"define_extents\">Define the Extents of the Analysis [&#9652;](#top)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Specify start and end dates in the same order as platforms and products**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use these four lines to select the time slice common to all products.\n",
    "# min_start_date_mutual = np.max(min_max_dates[:,0])\n",
    "# max_end_date_mutual = np.min(min_max_dates[:,1])\n",
    "# start_dates = [min_start_date_mutual, min_start_date_mutual]\n",
    "# end_dates = [max_end_date_mutual, max_end_date_mutual]\n",
    "# Use these two lines to select all data available to each product.\n",
    "# start_dates = min_max_dates[:,0]\n",
    "# end_dates = min_max_dates[:,1]\n",
    "\n",
    "# Select a subset of the time available.\n",
    "start_date, end_date = dt.datetime(2016,1,1), dt.datetime(2017,12,1)\n",
    "# start_date, end_date = dt.datetime(2014,9,1), dt.datetime(2015,3,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Specify an area to analyze**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify latitude and longitude bounds of an interesting area within the full extents\n",
    "\n",
    "# Ghana\n",
    "# min_lat_small, max_lat_small = (5.7261, 5.7390) # Crops NW of Accra (small)\n",
    "# min_lon_small, max_lon_small = (-0.4960, -0.4889) # Crops NW of Accra (small)\n",
    "# min_lat_small, max_lat_small = (5.7259, 5.7517) # Crops NW of Accra (medium)\n",
    "# min_lon_small, max_lon_small = (-0.5308, -0.5143) # Crops NW of Accra (medium)\n",
    "min_lat_small, max_lat_small = (8.0074, 8.0203) # Central Ghana - West of Kintampo\n",
    "min_lon_small, max_lon_small = (-2.0486, -2.0332) # Central Ghana - West of Kintampo\n",
    "    \n",
    "# Vietnam\n",
    "# min_lat_small, max_lat_small = (10.95, 11.00) # Area #1\n",
    "# min_lon_small, max_lon_small = (107.15, 107.20) # Area #1\n",
    "# min_lat_small, max_lat_small = (11.10, 11.39) # Area #2\n",
    "# min_lon_small, max_lon_small = (106.8, 106.92) # Area #2\n",
    "# min_lat_small, max_lat_small = (9.8, 10.0) # Area #3\n",
    "# min_lon_small, max_lon_small = (105.2, 105.4) # Area #3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize the selected area**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lon_small = (min_lon_small, max_lon_small)\n",
    "lat_small = (min_lat_small, max_lat_small)\n",
    "display_map(lat_small, lon_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id=\"retrieve_data\">Load Data from the Data Cube [&#9652;](#top)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_cube_utilities.dc_load import load_multiplatform\n",
    "\n",
    "measurements = ['red', 'blue', 'green', 'nir', 'swir1', 'swir2', 'pixel_qa']\n",
    "dataset, clean_mask, _ = \\\n",
    "    load_multiplatform(dc, platforms, products, \n",
    "                       load_params=dict(lat=lat_small, lon=lon_small, time=(start_date, end_date),\n",
    "                                        measurements=measurements))\n",
    "cleaned_dataset = dataset.where(clean_mask)\n",
    "del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id='calculate'>Calculate NDVI [&#9652;](#top)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils.data_cube_utilities.dc_ndvi_anomaly import NDVI\n",
    "ndvi_arr = NDVI(cleaned_dataset)\n",
    "cleaned_dataset['ndvi'] = ndvi_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id=\"area_analysis\">Examine the Selected Area [&#9652;](#top)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If no plots appear in the figures below, there is no data available for the region selected**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Box-and-Whisker Plot by Full Time Period, Week, Month, Week of Year, or Month of Year.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from utils.data_cube_utilities.plotter_utils import xarray_time_series_plot\n",
    "\n",
    "# Specify whether to plot a Gaussian curve fit of the mean of NDVI along time.\n",
    "plot_curve_fit_ndvi_mean = True\n",
    "max_times_per_plot = 10 # The maximum number of acquisitions with data that appear in each plot.\n",
    "\n",
    "# Can be one of [None, 'week', 'month', 'weekofyear', 'monthofyear'].\n",
    "for bin_by in ['monthofyear']:\n",
    "    aggregated_by_str = None\n",
    "    if bin_by is None:\n",
    "        plotting_data = cleaned_dataset\n",
    "    elif bin_by == 'week':\n",
    "        plotting_data = cleaned_dataset.resample(time='1w').mean()\n",
    "        aggregated_by_str = 'Week'\n",
    "    elif bin_by == 'month':\n",
    "        plotting_data = cleaned_dataset.resample(time='1m').mean()\n",
    "        aggregated_by_str = 'Month'\n",
    "    elif bin_by == 'weekofyear':\n",
    "        plotting_data = cleaned_dataset.groupby('time.week').mean(dim=('time'))\n",
    "        aggregated_by_str = 'Week of Year'\n",
    "    elif bin_by == 'monthofyear':\n",
    "        plotting_data = cleaned_dataset.groupby('time.month').mean(dim=('time'))\n",
    "        aggregated_by_str = 'Month of Year'\n",
    "    \n",
    "params = dict(dataset=plotting_data, plot_descs={'ndvi':{'none':[\n",
    "    {'box':{'boxprops':{'facecolor':'forestgreen'}}}]}})\n",
    "if plot_curve_fit_ndvi_mean:\n",
    "    params['plot_descs']['ndvi']['mean'] = [{'poly': {'degree': 3}}]\n",
    "    \n",
    "params['scale_params'] = 'norm'\n",
    "    \n",
    "xarray_time_series_plot(**params, fig_params=dict(figsize=(8,4), dpi=150))\n",
    "plt.title('Box-and-Whisker Plot by Full Time Period')\n",
    "print(\"NDVI {}\".format(\"(Aggregated by {})\".format(aggregated_by_str) if aggregated_by_str is not None else \"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id=\"mosaic\">Create a Max NDVI Composite [&#9652;](#top)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from utils.data_cube_utilities.dc_mosaic import create_max_ndvi_mosaic\n",
    "from utils.data_cube_utilities.dc_rgb import rgb\n",
    "max_ndvi_mosaic = create_max_ndvi_mosaic(cleaned_dataset, clean_mask)\n",
    "rgb(max_ndvi_mosaic)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id=\"export\">Export the Mosaic to a PNG and a GeoTIFF [&#9652;](#top)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Export to PNG**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_cube_utilities.dc_utilities import write_png_from_xr\n",
    "import os\n",
    "png_dir = 'output/pngs'\n",
    "if not os.path.exists(png_dir):\n",
    "    os.makedirs(png_dir)\n",
    "write_png_from_xr('{}/NDVI_Phenology_Max_NDVI_Mosaic.png'.format(png_dir), max_ndvi_mosaic, ['red','green','blue'], scale=(0,4000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Export to GeoTIFF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_cube_utilities.import_export import export_xarray_to_geotiff\n",
    "geotiff_dir = 'output/geotiffs/NDVI_Phenology'\n",
    "if not os.path.exists(geotiff_dir):\n",
    "    os.makedirs(geotiff_dir)\n",
    "export_xarray_to_geotiff(cleaned_dataset, \"{}/NDVI_Phenology\".format(geotiff_dir))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
