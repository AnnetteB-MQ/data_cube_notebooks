{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a>\n",
    "# NDVI Phenology\n",
    "<hr>\n",
    "\n",
    "# Notebook Summary\n",
    "\n",
    "* LANDSAT 7, LANDSAT 8, or both are used to detect changes in plant life over time.\n",
    "* Either NDVI or EVI may be used as a indicator of vegatation.\n",
    "* The outputs of this notebook can be used to assess differences in agriculture fields over time or space and also allow the assessment of growing states such as planting and harvesting.\n",
    "\n",
    "<hr><hr>\n",
    "\n",
    "# Algorithmic process  \n",
    "\n",
    "* [Import Dependencies and Connect to the Data Cube](#import)\n",
    "* [Choose Platform and Product](#plat_prod)\n",
    "* [Get the Maximum Extents of the Cube](#extents)\n",
    "* [Define the Extents of the Analysis](#define_extents) (selecting too much can make the acquisition process slow)\n",
    "* [Load Data from the Data Cube](#retrieve_data)\n",
    "* [Calculate Vegetation Index](#calculate)\n",
    "* [Examine the Selected Area](#area_analysis)\n",
    "* [Create a Max NDVI Composite](#mosaic)\n",
    "* [Export the Mosaic to a PNG and a GeoTIFF](#export)\n",
    "\n",
    "<hr><hr>\n",
    "\n",
    "# How It Works\n",
    "\n",
    "To detect changes in plant life, we use a measure called NDVI. \n",
    "* <font color=green>NDVI</font> is the ratio of the difference between the amount of near infrared light <font color=red>(NIR)</font> and red light <font color=red>(RED)</font> divided by their sum.\n",
    "<br>\n",
    "\n",
    "$$ NDVI =  \\frac{(NIR - RED)}{(NIR + RED)}$$  \n",
    "\n",
    "<br>\n",
    "<div class=\"alert-info\">\n",
    "The intention is to observe how much red light is being absorbed versus reflected. Photosynthetic plants absorb most of the visible spectrum's wavelengths when they are healthy. When they aren't healthy, more of that light will get reflected, making the difference between <font color=red>NIR</font> and <font color=red>RED</font> much smaller, which will lower the <font color=green>NDVI</font> value. So a higher NDVI indicates a higher degree of vegetation.\n",
    "</div>\n",
    "\n",
    "However, we can also use a measure called EVI.\n",
    "<br>\n",
    "\n",
    "$$ EVI =  G * \\frac{(NIR - RED)}{(NIR + C1*RED-C2*BLUE+L)}$$  \n",
    "\n",
    "<br>\n",
    "<div class=\"alert-info\">\n",
    "    EVI is superior to NDVI in accuracy because it is less dependent on the solar\n",
    "    incidence angle, atmospheric conditions (e.g. particles and clouds), shadows, and\n",
    "    soil appearance. Normally, $G=2.5$, $C1=6$, $C2=7.5$, and $L=1$.\n",
    "</div>\n",
    "\n",
    "Additionally, there is a 2-band version of EVI called EVI2.\n",
    "<br>\n",
    "\n",
    "$$ EVI2 = G * \\frac{(NIR - RED)}{(NIR + C*RED+L)}$$\n",
    "\n",
    "<br>\n",
    "<div class=\"alert-info\">\n",
    "    EVI2 does not require a blue band like EVI, which means less data is required to use it.\n",
    "    Additionally, the blue band used in EVI can have a low signal-to-noise ratio \n",
    "    in earth observation imagery. When atmospheric effects are insignificant (e.g. on clear days),\n",
    "    EVI2 should closely match EVI. Normally, $G=2.5$, $C=2.4$, and $L=1$.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id=\"import\">Import Dependencies and Connect to the Data Cube [&#9652;](#top)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "# Supress Warning \n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import the datacube and the API\n",
    "import datacube\n",
    "from utils.data_cube_utilities.data_access_api import DataAccessApi\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the datacube and API.\n",
    "api = DataAccessApi(config=\"/home/localuser/.datacube.conf\")\n",
    "dc = api.dc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id=\"plat_prod\">Choose Platform and Product [&#9652;](#top)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get available products\n",
    "products_info = dc.list_products()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List LANDSAT 7 products\n",
    "print(\"LANDSAT 7 Products:\")\n",
    "products_info[[\"platform\", \"name\"]][products_info.platform == \"LANDSAT_7\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# List LANDSAT 8 products\n",
    "print(\"LANDSAT 8 Products:\")\n",
    "products_info[[\"platform\", \"name\"]][products_info.platform == \"LANDSAT_8\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the platforms (satellites) and products (datacube sets) \n",
    "# used for this demonstration.\n",
    "use_Landsat7 = True\n",
    "use_Landsat8 = False\n",
    "platforms = []\n",
    "products = []\n",
    "if use_Landsat7:\n",
    "    platforms.append('LANDSAT_7')\n",
    "    products.append('ls7_ledaps_ghana')\n",
    "if use_Landsat8:\n",
    "    platforms.append('LANDSAT_8')\n",
    "    products.append('ls8_lasrc_ghana')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id=\"extents\">Get the Maximum Extents of the Cube [&#9652;](#top)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for product, platform in zip(products, platforms):\n",
    "    prod_extents = api.get_query_metadata(platform=platform, product=product, measurements=[])\n",
    "\n",
    "    latitude_extents = prod_extents['lat_extents']\n",
    "    longitude_extents = prod_extents['lon_extents']\n",
    "    time_extents = list(map(lambda time: time.strftime('%Y-%m-%d'), prod_extents['time_extents']))\n",
    "\n",
    "    print(\"{}:\".format(platform))\n",
    "    print(\"Lat bounds:\", latitude_extents)\n",
    "    print(\"Lon bounds:\", longitude_extents)\n",
    "    print(\"Time bounds:\", time_extents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from utils.data_cube_utilities.dc_load import get_overlapping_area\n",
    "from utils.data_cube_utilities.dc_display_map import display_map\n",
    "\n",
    "full_lat, full_lon, min_max_dates = get_overlapping_area(api, platforms, products)\n",
    "\n",
    "# Display the total shared area available for these datacube products.\n",
    "display_map(latitude = full_lat,longitude = full_lon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id=\"define_extents\">Define the Extents of the Analysis [&#9652;](#top)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Specify start and end dates in the same order as platforms and products**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use these four lines to select the time slice common to all products.\n",
    "# min_start_date_mutual = np.max(min_max_dates[:,0])\n",
    "# max_end_date_mutual = np.min(min_max_dates[:,1])\n",
    "# start_dates = [min_start_date_mutual, min_start_date_mutual]\n",
    "# end_dates = [max_end_date_mutual, max_end_date_mutual]\n",
    "# Use these two lines to select all data available to each product.\n",
    "# start_dates = min_max_dates[:,0]\n",
    "# end_dates = min_max_dates[:,1]\n",
    "\n",
    "# Select a subset of the time available.\n",
    "start_date, end_date = dt.datetime(2016,1,1), dt.datetime(2017,12,1)\n",
    "# start_date, end_date = dt.datetime(2014,9,1), dt.datetime(2015,3,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Specify an area to analyze**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify latitude and longitude bounds of an interesting area within the full extents\n",
    "\n",
    "# Ghana\n",
    "# min_lat_small, max_lat_small = (5.7261, 5.7390) # Crops NW of Accra (small)\n",
    "# min_lon_small, max_lon_small = (-0.4960, -0.4889) # Crops NW of Accra (small)\n",
    "# min_lat_small, max_lat_small = (5.7259, 5.7517) # Crops NW of Accra (medium)\n",
    "# min_lon_small, max_lon_small = (-0.5308, -0.5143) # Crops NW of Accra (medium)\n",
    "min_lat_small, max_lat_small = (8.0074, 8.0203) # Central Ghana - West of Kintampo\n",
    "min_lon_small, max_lon_small = (-2.0486, -2.0332) # Central Ghana - West of Kintampo\n",
    "    \n",
    "# Vietnam\n",
    "# min_lat_small, max_lat_small = (10.95, 11.00) # Area #1\n",
    "# min_lon_small, max_lon_small = (107.15, 107.20) # Area #1\n",
    "# min_lat_small, max_lat_small = (11.10, 11.39) # Area #2\n",
    "# min_lon_small, max_lon_small = (106.8, 106.92) # Area #2\n",
    "# min_lat_small, max_lat_small = (9.8, 10.0) # Area #3\n",
    "# min_lon_small, max_lon_small = (105.2, 105.4) # Area #3\n",
    "# min_lat_small, max_lat_small = (9.9, 10.1) # Area #4\n",
    "# min_lon_small, max_lon_small = (105.0, 105.2) # Area #4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize the selected area**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lon_small = (min_lon_small, max_lon_small)\n",
    "lat_small = (min_lat_small, max_lat_small)\n",
    "display_map(lat_small, lon_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id=\"retrieve_data\">Load Data from the Data Cube [&#9652;](#top)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from utils.data_cube_utilities.dc_load import load_multiplatform\n",
    "\n",
    "# Select which spectral index to use to track changes in vegetation.\n",
    "# Can be any of ['NDVI', 'EVI', 'EVI2'].\n",
    "spectral_index = 'EVI2'\n",
    "\n",
    "if spectral_index == 'NDVI':\n",
    "    measurements = ['red', 'nir']\n",
    "elif spectral_index == 'EVI':\n",
    "    measurements = ['red', 'nir', 'blue']\n",
    "else: # EVI2\n",
    "    measurements = ['red', 'nir']\n",
    "# Include pixel_qa band to obtain the clean mask in load_multiplatform.\n",
    "# Include red, green, and blue bands to be able to show RGB images of the data.\n",
    "measurements = list(set(measurements + ['pixel_qa', 'red', 'green', 'blue']))\n",
    "dataset, clean_mask, _ = \\\n",
    "    load_multiplatform(dc, platforms, products, \n",
    "                       load_params=dict(lat=lat_small, lon=lon_small, time=(start_date, end_date),\n",
    "                                        measurements=measurements))\n",
    "cleaned_dataset = dataset.where(clean_mask)\n",
    "del dataset # Save memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id='calculate'>Calculate Vegetation Index [&#9652;](#top)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_cube_utilities.dc_ndvi_anomaly import NDVI, EVI, EVI2\n",
    "\n",
    "if spectral_index == 'NDVI':\n",
    "    vegetation_arr = NDVI(cleaned_dataset)\n",
    "elif spectral_index == 'EVI':\n",
    "    vegetation_arr = EVI(cleaned_dataset)\n",
    "else: # 'EVI2'\n",
    "    vegetation_arr = EVI2(cleaned_dataset)\n",
    "cleaned_dataset[spectral_index] = vegetation_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id=\"area_analysis\">Examine the Selected Area [&#9652;](#top)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If no plots appear in the figures below, there is no data available for the region selected**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Box-and-Whisker Plot by Full Time Period, Week, Month, Week of Year, or Month of Year.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from utils.data_cube_utilities.plotter_utils import xarray_time_series_plot\n",
    "\n",
    "## Settings ##\n",
    "\n",
    "# Specify the type of curve fit to use for the vegetation index along time.\n",
    "# Can be one of [None, 'gaussian', 'gaussian_filter', 'poly', 'cubic_spline'].\n",
    "# Using None will not plot a curve fit.\n",
    "curve_fit_type = 'gaussian_filter'\n",
    "assert curve_fit_type in [None, 'gaussian', 'gaussian_filter', 'poly', 'cubic_spline'], \\\n",
    "    \"The variable `curve_fit_type` must be in \" \\\n",
    "    \"[None, 'gaussian', 'gaussian_filter', 'poly', 'cubic_spline']\"\n",
    "\n",
    "# Specify the target aggregation type of the curve fit. Input can be either 'mean' or 'median'.\n",
    "curve_fit_target = 'median'\n",
    "assert curve_fit_target in ['mean', 'median'], \"The variable 'curve_fit_target' must be either \"\\\n",
    "                                               \"'mean' or 'median'.\"\n",
    "\n",
    "# The maximum number of data points that appear along time in each plot.\n",
    "# If more than this number of data points need to be plotted, a grid of plots will be created.\n",
    "max_times_per_plot = 10\n",
    "\n",
    "## End Settings ##\n",
    "\n",
    "# Can be one of [None, 'week', 'month', 'weekofyear', 'monthofyear'].\n",
    "for bin_by in ['monthofyear']:\n",
    "    aggregated_by_str = None\n",
    "    if bin_by is None:\n",
    "        plotting_data = cleaned_dataset\n",
    "    elif bin_by == 'week':\n",
    "        plotting_data = cleaned_dataset.resample(time='1w').mean()\n",
    "        aggregated_by_str = 'Week'\n",
    "    elif bin_by == 'month':\n",
    "        plotting_data = cleaned_dataset.resample(time='1m').mean()\n",
    "        aggregated_by_str = 'Month'\n",
    "    elif bin_by == 'weekofyear':\n",
    "        plotting_data = cleaned_dataset.groupby('time.week').mean(dim=('time'))\n",
    "        aggregated_by_str = 'Week of Year'\n",
    "    elif bin_by == 'monthofyear':\n",
    "        plotting_data = cleaned_dataset.groupby('time.month').mean(dim=('time'))\n",
    "        aggregated_by_str = 'Month of Year'\n",
    "    \n",
    "params = dict(dataset=plotting_data, \n",
    "              plot_descs={spectral_index:{'none':[{'box':{'boxprops':{'facecolor':'forestgreen'}}}]}})\n",
    "if curve_fit_type is not None:\n",
    "    if curve_fit_type == 'gaussian':\n",
    "        curve_fit_desc = [{'gaussian': {}}]\n",
    "    elif curve_fit_type == 'gaussian_filter':\n",
    "        curve_fit_desc = [{'gaussian_filter': {}}]\n",
    "    elif curve_fit_type == 'poly':\n",
    "        curve_fit_desc = [{'poly': {'degree': 3}}]\n",
    "    else: # 'cubic_spline'\n",
    "        curve_fit_desc = [{'cubic_spline': {}}]\n",
    "    params['plot_descs'][spectral_index][curve_fit_target] = curve_fit_desc\n",
    "    \n",
    "params['scale_params'] = 'norm'\n",
    "    \n",
    "xarray_time_series_plot(**params, fig_params=dict(figsize=(8,4), dpi=150))\n",
    "plt.title('Box-and-Whisker Plot by Full Time Period')\n",
    "agg_str = \"(Aggregated by {})\".format(aggregated_by_str) if aggregated_by_str is not None else \"\"\n",
    "print(\"{} {}\".format(spectral_index, agg_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id=\"mosaic\">Create a Max NDVI Composite [&#9652;](#top)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from utils.data_cube_utilities.dc_mosaic import create_max_ndvi_mosaic\n",
    "from utils.data_cube_utilities.dc_rgb import rgb\n",
    "\n",
    "max_ndvi_mosaic = create_max_ndvi_mosaic(cleaned_dataset, clean_mask)\n",
    "rgb(max_ndvi_mosaic, use_data_min=True, use_data_max=True, min_inten=0.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span id=\"export\">Export the Mosaic to a PNG and a GeoTIFF [&#9652;](#top)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Export to PNG**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_cube_utilities.dc_utilities import write_png_from_xr\n",
    "import os\n",
    "png_dir = 'output/pngs'\n",
    "if not os.path.exists(png_dir):\n",
    "    os.makedirs(png_dir)\n",
    "write_png_from_xr('{}/NDVI_Phenology_Max_NDVI_Mosaic.png'.format(png_dir), max_ndvi_mosaic, ['red','green','blue'], scale=(0,4000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Export to GeoTIFF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from utils.data_cube_utilities.import_export import export_xarray_to_geotiff\n",
    "geotiff_dir = 'output/geotiffs/NDVI_Phenology'\n",
    "if not os.path.exists(geotiff_dir):\n",
    "    os.makedirs(geotiff_dir)\n",
    "export_xarray_to_geotiff(cleaned_dataset, \"{}/NDVI_Phenology\".format(geotiff_dir))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
